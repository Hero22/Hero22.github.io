<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kong Kim in plane]]></title>
    <url>%2F2020%2F10%2F14%2FKong-Kim-in-plane%2F</url>
    <content type="text"><![CDATA[金刚坐飞机问题，有一班飞机要起飞，乘客们正准备按机票号码（1，2，…，N）依次登机。突然来了个金刚，他也有飞机票，但是他插队第一个上了飞机，随机选个座位坐下了。其他乘客有两种反应： 他们也随意找个位置坐下； 如果自己座位没有被占领，就坐自己的位置，否则随意找个位置坐下。 在这两种情况下，第i个乘客（除去金刚外）坐到自己原机票位置的概率分别是多少？ Q1要保证第i个乘客坐到自己的位置上，则前i-1个乘客包括金刚都别坐到第i个人的座位，第i个人就有机会坐到自己的位置，得到概率公式为：$$f(i)=\frac{N-1}{N}\frac{N-2}{N-1}\dots\frac{N-i+1}{N-i+2}\frac{1}{N-i+1}=\frac{1}{N} （1）$$ Q2由于当乘客座位没人坐的时候，他会优先选自己的座位，那么设金刚坐在n号位置，当n=1/n&gt;j，即在最开始时，前i个人的座位都保留着，那么他们上机后都会坐自己的座位；当n=i时，第i个人肯定坐不到自己的位置了；比较麻烦的就是当金刚在1&lt;n&lt;i之间的情况，此时2~n-1这几位乘客还是能坐到自己的位置，而第n位乘客肯定坐不到自己的位置了，他要开始随便坐了，既然他都随便坐了，那和金刚有什么区别？因此我们换种想法： 即把金刚当作第n个人，而真正的第n人当作金刚，只不过该虚假的金刚和真正的金刚还是有点差别的，那就是他没有真正金刚那么多的座位选择，这个假金刚只能从剩下的N-n+1个座位里边选一个坐（1， n+1，n+2，…，N）。如此一来，当金刚坐在第n个座位（1&lt;n&lt;i）时，第i个人坐到自己座位的概率就变成了：$$f(n)=\sum_j \frac{1}{N-n+1}f(j),(j=1,n+1,…,N)（2）$$由该递推式，进一步可以得到n=n+1时的情况，即：$$f(n+1)=\sum_j \frac{1}{N-n}f(j),(j=1,n+2,…,N)（3）$$上述两个式子相减，即得到：$$(N-n)[f(n)-f(n+1)]=f(n+1)-f(n) =&gt; f(n)=f(n+1),(1&lt;n&lt;i-1)（4）$$最终可得：$$f(n)=\frac{N-i+1}{N-i+2}（5）$$在不同情况下的f(n)都已求得，最后在把所有情况概率和相加即可：$$\sum_{n=1}^N \frac{1}{N}f(n)=\frac{N-i+1}{N-i+2}（6）$$ 扩展上述两种情况都假设乘客按照顺序上机，那如果乘客上机的顺序也是随机，第i个乘客上机坐到自己位置的概率怎么算呢？ 对第一种情况影响不大，因为所有人就算是按顺序上机，座位也是随便坐的，和随便登机没差。 第二种情况下，当金刚坐在n号座位时，如果紧接着就是第n个人登机，那么他完全有可能坐到前n个人的座位，Orz]]></content>
      <tags>
        <tag>kong kim</tag>
        <tag>probability</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[poj2411]]></title>
    <url>%2F2020%2F10%2F12%2Fpoj2411%2F</url>
    <content type="text"><![CDATA[用1*2的长方形, 可以横着放，也能竖着放，填充高为h，宽为w的面积，问有多少种铺法? 原址 分析理解他人的思想后，我画几张图进行补充 1）考虑最后一块的情况，如图1，其中黑色的表示已经覆盖了的，白色的表示还没覆盖的（先不要考虑黑色部分是如何覆盖的） 在这种情况下，是没法把全部方块覆盖完的。 接着最后一块的另一种情况，如图2， 如果最后一块被覆盖了，说明任务完成。 2）在考虑最后两块没填的情况，一共有四种可能（00，01，10，11/0表示没填，1表示填了），这里先看00的情况，图3: 这时候刚好可以横着放下一块，因此存在一种覆盖方法。如果是01，图4：这种情况也没法填满了。 （注意这里的状态表示是从最先的未填充的格子开始记的，因此状态码转换为二进制后，最低位表示的是最先未填充的格子，是反着来的，比如虽然上述状态为01，但其实记为状态2，究其原因是倒着从右往左，从下到上导致的，既然这样可以，那顺着从上到下，从左到右也是可以的，那样状态码就不用逆着了） 如果是10，如图5，该填的倒数第二个各自已经填过了，这时候就看倒数第一个格子在当前状态下(没填)，它有几种填充方案，会发现，此时就到了图1的情况了。 因此可以考虑将前面的状态保存起来，让后面的遍历可以直接查询值就好（前提是后边的状态在处理过程中和前边的状态一致了）。 那么要保存多少个状态呢，需要保存一行的状态，每个格子两种状态，一行就是pow(2, w)中状态。（为什么要保存一行的状态呢，保存半行，两行行不行呢） 就是说，对于图6箭头所指的方块来说，它要考虑紫线覆盖的方格的所有的状态。 当遍历到的状态，该格子为0（没填）时，就需要看能不能横着放，能不能竖着放；如果该格子为1，说明填过了，那么该状态下可能的填充方案就取决于前边格子在当前状态下填充的方案。 下面分别考虑这三种情况： 横着放，判断右边是否超边界，且右边的格子状态为0，不然右边格子都填过了，还怎么填。假设当前判断的状态为00000000，那么可以横着放，放下去之后如下图所示： 这样一来，就多了好多种摆放的方法了，具体多少种呢，只要去查右边的格子，处于状态10000000有多少种填充方法即可。 竖着放，竖着放只需要看竖着是否超边界就行，至于当前格子下边那个格子的状态是不用考虑的，因为就保存的一行状态来说，也没保存到它，不如就默认下边的没填，然后更新状态后再去处理，比如这里选择状态为00110101，如下图所示： 这样一来，又多了几种摆放方法，多了右边格子处于状态01101011（就是去掉当前状态的低位，最高位置为1） 已填，比如处理到状态11000011时，如下图所示，（此时处理的格子为绿色箭头指的）此时该状态下的填充方法，取决于下一个格子（也就是右边，到了边界就是下一行的开头格子）处于10000110状态下的填充方法，注意这时候可不用加了，因为这种情况，本质上并没有引入新的摆放方法。可以考虑图3所示的情况，假如此时处理的是第三个格子（及两白色左边的黑格子），那么状态就为100了，由于第三个格子状态为1，已经填过了，此状态下，具体有多少种填充方法就看两个白格子了（就一种咯）。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Poj2411 &#123; public static void main(String[] args) &#123; System.out.println(filledWithRec(4, 11)); &#125; public static int filledWithRec(int h, int w) &#123; if ((h*w &amp; 1) == 1) return 0; int[][][] dp = new int[h][w][1 &lt;&lt; w]; // dp[i][j][k] represent how many different ways to cover the remainder place after (i, j) at status k dp[h - 1][w - 1][0] = 0; dp[h - 1][w - 1][1] = 1; int[] next = &#123;-1, -1&#125;; for (int i = h - 1; i &gt;= 0; i--) &#123; for (int j = w - 1; j &gt;= 0; j--) &#123; boolean hasNext = hasNext(i, j, h, w, next); for (int k = 0; k &lt; (1 &lt;&lt; w); k++) &#123; // if (i, j) is filled if ((k &amp; 1) == 1) &#123; if (hasNext) dp[i][j][k] = dp[next[0]][next[1]][k&gt;&gt;&gt;1]; &#125; else &#123; // fill (i, j) with a 1*2 row, with status 00... if (j+1&lt;w &amp;&amp; ((k&amp;2) == 0)) &#123; dp[i][j][k] += dp[next[0]][next[1]][(k|2)&gt;&gt;&gt;1]; &#125; // fill (i, j) with a 2*1 column if (i+1 &lt; h) &#123; dp[i][j][k] += dp[next[0]][next[1]][(k&gt;&gt;&gt;1)|(1&lt;&lt;(w-1))]; &#125; &#125; &#125; &#125; &#125; return dp[0][0][0]; &#125; public static boolean hasNext(int i, int j, int h, int w, int[] next) &#123; if (i == h - 1 &amp;&amp; j == w - 1) return false; next[1] = (j + 1) % w; next[0] = j == w - 1 ? i + 1 : i; return true; &#125;&#125;]]></content>
      <tags>
        <tag>poj</tag>
        <tag>状态dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的String]]></title>
    <url>%2F2020%2F07%2F31%2Fstring-in-java%2F</url>
    <content type="text"><![CDATA[123456789101112// 看看最后判断的结果是什么 -----------jdk1.8之后-------------public static void main(String[] args) &#123; String str = new StringBuilder("str").append("str").toString(); String str1 = new String("str1"); String str2 = "str1"; System.out.println(str == str.intern()); System.out.println(str1 == str1.intern()); System.out.println(str2 == str1.intern());&#125; 123System.out.println(str == str.intern()); // trueSystem.out.println(str1 == str1.intern()); // falseSystem.out.println(str2 == str1.intern()); // true 看到JVM中提到的各种常量池，我真是 其中当然也包括字符串常量池(StringTable)，看了网上众说纷，我真是 下面用几个简单的示例，来看看用JHSDB看到的东西，先看 case11234public static void main(String[] args) &#123; String str = new StringBuilder("str").append("str").toString(); System.out.println("debug");&#125; 在上述输出语句打上断点，用jps查看进程id，用jhsdb hsdb --pid id连上该进程 依次点击Tools-&gt;Object Histogram, 在列出来的类中双击String类型，然后找到上边写的str串，如下图 发现如下三点： 字符串已经排好序了 只有一个str 只有一个strstr 通过依次点击Tools-&gt;Heap Parameters，可以看到当前堆的地址范围，比较得知，上述提到的两个字符串的地址是在堆范围内的。 case21234public static void main(String[] args) &#123; String str1 = new String("str1"); System.out.println("debug");&#125; 这次只修改了字符串的声明，仍然按照上述步骤，看到的信息如下 发现这里出现了两个str1，继续 case31234public static void main(String[] args) &#123; String str = new StringBuilder("str").append("str1").toString(); System.out.println("debug");&#125; 对case1进行修改，append一个不一样的串，结果如下 在类似的地址上找到了三个串，继续变 case41234public static void main(String[] args) &#123; String str = new StringBuilder("str").toString(); System.out.println("debug");&#125; 这次也不追加了，就一个，结果如下 结果和case2一样，继续 case51234public static void main(String[] args) &#123; String str2 = "str2"; System.out.println("debug");&#125; 结果如下，只有一个串 下面对上边五种情况作个小结，含有猜的成分 字符串还是放在堆上的，至于字符串常量池这个概念，里边放的到底是什么，就上边几个简单例子来看，是不会放字符串本身的，也就只能放引用了 程序中被双引号引起来的字符串，都会先到堆中，重复的不会重复放(对比case1和case3) 对于new操作，会把最终合成的字符串(new String(&quot;a&quot;)+new String(&quot;b&quot;), new StringBuilder(&quot;a&quot;).append(&quot;b&quot;), 以及new String(&quot;a&quot;).concat(&quot;b&quot;)生成的&quot;ab&quot;或单纯的new String(&quot;ab&quot;))在堆中创建一遍(对比case1/2/3/4) 字符串常量池中放的引用其实是指向堆中的字符串的，而且不会重复(即使堆中有多个字面量相同的字符串，字符串常量池中也只会有一个指向该字面量的引用) 这样一来，在对开头的示例进行解释 str == str.intern() 在为str赋值时，加引号的&quot;str&quot;先被创建且其对应的引用也放到字符串常量池中了，然后在堆上创建&quot;strstr&quot;对象，此时还没放到字符串常量池中，在调用str的intern()方法时将其引用放到了字符串常量池中，因此str和str.intern()实际上都指向的是同样一个对象, 返回true str1 == str1.intern() 根据前边的小结，在执行String str1 = new String(&quot;str1&quot;);时，首先根据双引号，在堆中创建了一个&quot;str1&quot;串，记为H1, 然后将其引用放入字符串常量池中，接着又在堆中new了另外一个&quot;str1&quot;, 记为H2, 此时H2可不会再放到字符串常量池中了，结果str1 ---&gt; H2，str1.intern() ---&gt; H1，他们指向不同的地址，返回false str2 == str1.intern() 由于str2在创建时，发现字符串常量池已经有指向&quot;str1&quot;字面值的引用了，因此直接返回了，相当与str2 ---&gt; H1 &lt;--- str1.intern()，指向相同的地址，返回true 再对这个例子画个小图 最后再引用一些其他说法 http://tangxman.github.io/2015/07/27/the-difference-of-java-string-pool/ 提到了一句话：全局字符串池里的内容是在类加载完成，经过验证，准备阶段之后在堆中生成字符串对象实例，然后将该字符串对象实例的引用值存到string pool中 再结合上图，如果这句话没错的话，那么灰色的字符串是在准备阶段后生成的，而白色的则是在程序运行过程中生成的 https://www.zhihu.com/question/57109429 根据RednaxelaFX的回答，StringTable放置于native memory中，且只存放引用]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>字符串常量池</tag>
        <tag>StringTable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建其他类中非静态内部类]]></title>
    <url>%2F2020%2F07%2F30%2Fcreate-not-static-inner-class-instance%2F</url>
    <content type="text"><![CDATA[123456789101112public class JHSDB_TestCase &#123; class NoStaticTest &#123;&#125;&#125;class Outter &#123; private void test() &#123; JHSDB_TestCase jhsdb_testCase = new JHSDB_TestCase(); JHSDB_TestCase.NoStaticTest noStaticTest = jhsdb_testCase.new NoStaticTest(); &#125;&#125;]]></content>
      <tags>
        <tag>内部类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泛型中的extend和super]]></title>
    <url>%2F2020%2F04%2F29%2Fgenerics%2F</url>
    <content type="text"><![CDATA[在java中经常会看到泛型中使用&lt;? extends T&gt;/&lt;? super T&gt; ，这个回答很好，这里记下我看后的思考。 &lt; ? extends T&gt;当声明了这样的一个泛型后，实际上其可以指向T或其子类的泛型，主要的一个点是在运行之前，无法确定到底指向的是哪个类型的泛型： 这时JVM为了避免实际指向的类型Tsub1和你想放进去的类型Tsub2产生冲突，所以干脆就不让put了。 但是读取的时候，完全可以按照T来读取所有的内容，可以理解为多态，父类型引用指向子类型对象，一样可以操作，所以可以get. &lt;? super T&gt;这样声明的话，实际上可以指向T或其父类的泛型，同样运行之前无法确定实际指向的类型： 不论指向的是T或其父类型，都能保证T或其子类可以put进去，同样是父类引用指向子类对象，没毛病。 但是读取的时候就出现问题了，如果不考虑根父类Object，不同类型的东西读出来的时候没有一个统一的类型，不像上边可以统一按照类型T读取。真的想拿出的话就只能按Object拿了。 PECS一般这个东西都会带一起看，是Producer Extends， Consumer Super的简称，这句话站在集合的角度看比较容易理解 如果集合作为Producer，那么其他的消费者就要从这个集合中拿东西，相当与get多，就选用extends 如果集合作为Consumer，那么它就要从别的生产者那里拿东西放到自己里边，相当于put多，就选用super]]></content>
      <tags>
        <tag>泛型</tag>
        <tag>generics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[install mysql]]></title>
    <url>%2F2020%2F03%2F09%2Finstall-mysql%2F</url>
    <content type="text"><![CDATA[在windows中使用数据库，首先下载，太慢的话可以去TUNA 以管理员身份到安装目录下的bin目录下： mysqld --initialize --console 会生成一个随机密码 mysqld --install 安装服务 net start MySQL 启动服务 alter user root@localhost identified by &#39;new pass&#39; 登陆后修改密码 set global time_zone=&#39;+8:00&#39; 设置时区 其他的设置可以查下配置文件my.ini]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis--集群(cluster)]]></title>
    <url>%2F2020%2F02%2F28%2Fredis-9%2F</url>
    <content type="text"><![CDATA[集群的作用： 分散单台服务器的访问压力，实现负载均衡 分散单台服务器的存储压力，实现可扩展性 降低单台服务器宕机带来的业务灾难 数据存储设计 计算key应该放在哪个槽位slot —–&gt; CRC16(key)—–&gt;%16384 集群就是对16384个槽位的分配，每台机器上都有记录所有槽位的分配 对多两次就可命中 相关配置 开启集群 —–&gt; cluster-enabled yes 集群配置文件 —-&gt; cluster-config-file nodes-6379.conf 这个文件是由redis自己管理的，如果一个机器上跑了多个集群节点注意文件名不要一样，否则会覆盖，影响集群 超时时间 —-&gt;cluster-node-timeout 15000 启动集群用的5.0.5版本已经不推荐使用redis-trib.rb脚本来启动集群了。 redis-cli --cluster help会显示详细的使用。 12create host1:port1 ... hostN:portN --cluster-replicas &lt;arg&gt; 创建集群 —-&gt; ./src/redis-cli --cluster create 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 --cluster-replicas 1 端口号后边跟的参数表明一个master会有几个slave，从前往后排，前面的是master，后边的为slave，当指定的个数有误时： 1234*** ERROR: Invalid configuration for cluster creation.*** Redis Cluster requires at least 3 master nodes.*** This is not possible with 6 nodes and 3 replicas per node.*** At least 12 nodes are required. 成功启动集群： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@localhost redis-5.0.5]# ./src/redis-cli --cluster create 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 --cluster-replicas 1&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 127.0.0.1:6383 to 127.0.0.1:6379Adding replica 127.0.0.1:6384 to 127.0.0.1:6380Adding replica 127.0.0.1:6382 to 127.0.0.1:6381&gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity[WARNING] Some slaves are in the same host as their masterM: 8608aea70c528e8f632c083b79e44a4782630437 127.0.0.1:6379 slots:[0-5460] (5461 slots) masterM: 82829a4cfa624c3d658e33d66b67d7cfb374d5ea 127.0.0.1:6380 slots:[5461-10922] (5462 slots) masterM: ee723da8dfb10b775570b9069f2fb17bff291e9f 127.0.0.1:6381 slots:[10923-16383] (5461 slots) masterS: c5ea0e80c1597c349753b7191cf9bc529e6c5b56 127.0.0.1:6382 replicates ee723da8dfb10b775570b9069f2fb17bff291e9fS: 03ff774a84676e19076bd93327ec00c85c6ee015 127.0.0.1:6383 replicates 8608aea70c528e8f632c083b79e44a4782630437S: 3867efa8d6dd57f7688f0e78e3f7c098d5b0654f 127.0.0.1:6384 replicates 82829a4cfa624c3d658e33d66b67d7cfb374d5eaCan I set the above configuration? (type &apos;yes&apos; to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join......&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:6379)M: 8608aea70c528e8f632c083b79e44a4782630437 127.0.0.1:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s)M: ee723da8dfb10b775570b9069f2fb17bff291e9f 127.0.0.1:6381 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: c5ea0e80c1597c349753b7191cf9bc529e6c5b56 127.0.0.1:6382 slots: (0 slots) slave replicates ee723da8dfb10b775570b9069f2fb17bff291e9fM: 82829a4cfa624c3d658e33d66b67d7cfb374d5ea 127.0.0.1:6380 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 03ff774a84676e19076bd93327ec00c85c6ee015 127.0.0.1:6383 slots: (0 slots) slave replicates 8608aea70c528e8f632c083b79e44a4782630437S: 3867efa8d6dd57f7688f0e78e3f7c098d5b0654f 127.0.0.1:6384 slots: (0 slots) slave replicates 82829a4cfa624c3d658e33d66b67d7cfb374d5ea[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 若要使用集群，再连接的时候需要加上-c参数 下线 如果slave掉线，和其相连的master过了超时时间后会将其标记—&gt; Marking node c5ea0e80c1597c349753b7191cf9bc529e6c5b56 as failing (quorum reached). 且会通知其他的所有节点，其他节点会收到一个消息: FAIL message received from ee723da8dfb10b775570b9069f2fb17bff291e9f about c5ea0e80c1597c349753b7191cf9bc529e6c5b56 在实验的时候发现一个也会这样，停掉一台slave，有两台master进行标记，该slave重连后，其中一台master(该从机的)是正常的和它进行同步，另外一台master和其他节点一样清除该标记 Clear FAIL state for node c5ea0e80c1597c349753b7191cf9bc529e6c5b56: replica is reachable again. 所以说并不一定是slave的master进行标记通知，也可能是其他的master发现该slave掉线进行标记通知 如果是master掉线，其slave会变为master： 1995:S 08 Mar 2020 01:22:34.810 # Start of election delayed for 791 milliseconds (rank #0, offset 1722). 1995:S 08 Mar 2020 01:22:34.810 # Cluster state changed: fail 1995:S 08 Mar 2020 01:22:35.214 * Connecting to MASTER 127.0.0.1:6379 1995:S 08 Mar 2020 01:22:35.215 * MASTER &lt;-&gt; REPLICA sync started 1995:S 08 Mar 2020 01:22:35.215 # Error condition on socket for SYNC: Connection refused 1995:S 08 Mar 2020 01:22:35.620 # Starting a failover election for epoch 7. 1995:S 08 Mar 2020 01:22:37.208 # Failover election won: I&#39;m the new master. 原master重连后，会变为新master的slave]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis--哨兵(sentinel)]]></title>
    <url>%2F2020%2F02%2F27%2Fredis-8%2F</url>
    <content type="text"><![CDATA[哨兵（监视别人工作）的作用： 监控： 不断检测master和slave是否正常运行 通知： 当被监控的服务器出现问题时，通知其他哨兵，客户端 自动故障转移 断开master与slave连接，选取一个slave作为master，将其他slave连接到新的master，并告知客户端新的服务器地址 配置redis提供的默认哨兵配置文件为sentinel.conf，常用配置包括：（部分和redis相同配置忽略） sentinel monitor mymaster 127.0.0.1 6379 2 其中mymaster为自定义的名称，后面地址和端口号是要监视的master的，最后的2表示后面的投票至少2票就通过 sentinel down-after-milliseconds mymaster 30000 经过多久master没有反应就认为它S_DOWN（主观掉线）了，因为这是是某一个哨兵发现的，是这个哨兵的主观行为，后续这个哨兵会通知其他哨兵，其他哨兵也会去hello这master，当有2个哨兵都认为它S_DOWN了之后，就确定该master为O_DOWN（客观掉线），大众的看法 sentinel parallel-syncs mymaster 1 设定一次可以有多少的slave能同时和新master进行同步 sentinel failover-timeout mymaster 180000 故障转移超时时间，同步超时时间？配置文件里的注释有点看不懂 监控阶段 sentinel首先会查询master相关信息（info），随后建立cmd连接，根据得到的信息再去获取slave的信息 sentinel之间通过pub/sub分享自己获取的信息 通知阶段 sentinel向master及slave发送消息publish sentinel:hello......，来确认这些点工作是否正常 sentinel向其他sentinel通知上述得到的结果 故障转移阶段 某个sentinel发现和master失去了连接，判断为S_DOWN，通知其他sentinel 其他sentinel也去尝试联系master，半数以上的sentinel认为master挂了后，判定为O_DOWN sentinel们竞选出一个负责处理此次事件的负责人，大家投票 负责人进行处理，挑选备选master 在线的 响应快的 和原master通信较近，丢失数据少的 优先原则（优先级/offset/runid） sentinel向新的master发送replicaof no one， 向其他的slave发送replicaof &lt;newmasterip&gt; &lt;newmasterport&gt;]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis--主从复制]]></title>
    <url>%2F2020%2F02%2F26%2Fredis-7%2F</url>
    <content type="text"><![CDATA[主从复制： 读写分离 负载均衡 故障恢复 数据冗余 高可用基石 总述主从复制过程大致可分为三个阶段： 建立连接阶段 数据同步阶段 命令传播阶段 建立连接有三种方式完成连接：（设有两台redis服务器，一台叫master，一台叫slave） 在slave客户端使用命令 slaveof masterhost masterport 在slave服务器端启动时，附加--slaveof masterhost masterport 在slave的配置文件中加上slaveof masterhost masterport ————&gt; 提供的redis.conf中并没有该选项，改为replicaof &lt;masterip&gt; &lt;masterport&gt;了，而且示意图中也变为Master----&gt;Replica redis服务器有两种方式设置密码： 在配置文件中requirepass &lt;password&gt; 在运行时通过客户端设置：config set requirepass &lt;password&gt;, 重启服务器会失效 设置密码后，如果没有进行认证，在客户端的大部分操作（没有验证所有的）都会：NOAUTH Authentication required. 两种认证方式： 启动redis客户端时附加-a | -u &lt;password&gt;，会提示可能不安全 连接后在客户端使用命令auth &lt;password&gt; 如果master设置了密码，slave想要连接master,需要在配置文件中提前设置masterauth &lt;password&gt;，应该只有这一种方式。 数据同步数据同步是由slave端发起的，可以通过master日志看出：Replica [::1]:6379 asks for synchronization 数据同步大致分为两个阶段： 全量复制，master进行bgsave，把得到的RDB文件通过socket发送给slave 增量/部分复制，在master进行bgsave时，可能又修改了某些数据，会将这些修改数据的指令存储在复制缓冲区中，全量复制完成后，在发送给slave，可以看作AOF ​ 注意：复制缓冲区存在溢出的情形，如果溢出，会再次进行全量复制，可能会陷入死循环 相关指令： 设置该缓冲区的大小：repl-backlog-size 1mb 进行复制时slave是否提供读服务：replica-serve-stale-data yes——-&gt;default slave是否提供写服务：replica-read-only yes———-&gt;default 命令传播第⑤步中使用的指令为：replconf ack &lt;offset&gt;]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis--删除策略]]></title>
    <url>%2F2020%2F02%2F25%2Fredis-6%2F</url>
    <content type="text"><![CDATA[包含两个部分，一是内存空间还有剩余，但是执行DEL等删除键的操作；二是内存空间不够了，类似GC随机删除某些键。 数据删除配置文件中的LAZY FREEING部分讲述了两种删除键的机制： 定时删除blocking deletion 即删除键时是一个阻塞操作，调用的时候就必须要进行删除，等不得，相当于时间换空间 DEL 操作 内存不够，需要阻塞删除 maxmemory 60Mb 设置过期时间，到时间阻塞删除 expire 更新值时，会阻塞删除旧值，比如 rename ,sunionstore, set 主从复制时，加载主机的RDB文件时要先删除所有库的内容 惰性删除 non-blocking 数据到期时并不一定马上删除，等下次访问时，先判断是否过期，未过期返回，已过期再删除，空间换时间 unlink 非阻塞删除 async选项，如flushdb async 配置文件中提供配置选项 lazyfree-lazy-eviction|expire|server-del no, replica-lazy-flush no 在查询键时，首先会调用expireIfNeeded方法 123456789101112131415161718192021int expireIfNeeded(redisDb *db, robj *key) &#123; if (!keyIsExpired(db,key)) return 0; /* If we are running in the context of a slave, instead of * evicting the expired key from the database, we return ASAP: * the slave key expiration is controlled by the master that will * send us synthesized DEL operations for expired keys. * * Still we try to return the right information to the caller, * that is, 0 if we think the key should be still valid, 1 if * we think the key is expired at this time. */ if (server.masterhost != NULL) return 1; // 如果是slave的话 /* Delete the key */ server.stat_expiredkeys++; // 在master中进行删除 propagateExpire(db,key,server.lazyfree_lazy_expire); notifyKeyspaceEvent(NOTIFY_EXPIRED, "expired",key,db-&gt;id); return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) : //可配置 dbSyncDelete(db,key); //的关键字&#125; 定期删除 serverCron()是一个定期执行的函数，需要执行一系列的任务，由server.hz设定工作周期，即每秒执行server.hz次，默认是10, 其完成的工作中第一项：Active expired keys collection (it is also performed in a lazy way on lookup),具体工作在databasesCron()中进行： 123456789101112void databasesCron(void) &#123; /* Expire keys by random sampling. Not required for slaves * as master will synthesize DELs for us. */ if (server.active_expire_enabled) &#123; if (server.masterhost == NULL) &#123; // 如果是master的话，执行删除 activeExpireCycle(ACTIVE_EXPIRE_CYCLE_SLOW); &#125; else &#123; expireSlaveKeys(); &#125; &#125; ...&#125; 继续到activeExpireCycle()方法中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107void activeExpireCycle(int type) &#123; /* This function has some global state in order to continue the work * incrementally across calls. */ static unsigned int current_db = 0; /* Last DB tested. */ static int timelimit_exit = 0; /* Time limit hit in previous call? */ static long long last_fast_cycle = 0; /* When last fast cycle ran. */ int j, iteration = 0; int dbs_per_call = CRON_DBS_PER_CALL; // 默认是16 long long start = ustime(), timelimit, elapsed; ... /* We usually should test CRON_DBS_PER_CALL per iteration, with * two exceptions: * * 1) Don't test more DBs than we have. * 2) If last time we hit the time limit, we want to scan all DBs * in this iteration, as there is work to do in some DB and we don't want * expired keys to use memory for too much time. */ if (dbs_per_call &gt; server.dbnum || timelimit_exit) dbs_per_call = server.dbnum; // 如果设置库大于16个，并且 // 检验超时了，下次循环就设为16次？ /* We can use at max ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC percentage of CPU time * per iteration. Since this function gets called with a frequency of * server.hz times per second, the following is the max amount of * microseconds we can spend in this function. */ // cpu时间的1/4 timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;//250ms timelimit_exit = 0; if (timelimit &lt;= 0) timelimit = 1; if (type == ACTIVE_EXPIRE_CYCLE_FAST) timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION; /* in microseconds. */ /* Accumulate some global stats as we expire keys, to have some idea * about the number of keys that are already logically expired, but still * existing inside the database. */ long total_sampled = 0; long total_expired = 0; for (j = 0; j &lt; dbs_per_call &amp;&amp; timelimit_exit == 0; j++) &#123;// 遍历16次库 int expired; redisDb *db = server.db+(current_db % server.dbnum); // 接着上次的跑 current_db++; // 记录当前的遍历到的库 /* Continue to expire if at the end of the cycle more than 25% * of the keys were expired. */ do &#123; ... /* If there is nothing to expire try next DB ASAP. */ if ((num = dictSize(db-&gt;expires)) == 0) &#123; db-&gt;avg_ttl = 0; break; &#125; slots = dictSlots(db-&gt;expires); now = mstime(); /* When there are less than 1% filled slots getting random * keys is expensive, so stop here waiting for better times... * The dictionary will be resized asap. */ if (num &amp;&amp; slots &gt; DICT_HT_INITIAL_SIZE &amp;&amp; (num*100/slots &lt; 1)) break; // 过期的太少了先跳过 /* The main collection cycle. Sample random keys among keys * with an expire set, checking for expired ones. */ ... if (num &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP) num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP; //默认20 while (num--) &#123; dictEntry *de; long long ttl; // 从当前库中的expire中随机挑选一个key if ((de = dictGetRandomKey(db-&gt;expires)) == NULL) break; ttl = dictGetSignedIntegerVal(de)-now; if (activeExpireCycleTryExpire(db,de,now)) expired++;//实际删除 if (ttl &gt; 0) &#123; /* We want the average TTL of keys yet not expired. */ ttl_sum += ttl; ttl_samples++; &#125; total_sampled++; &#125; total_expired += expired; /* Update the average TTL stats for this database. */ ... /* We can't block forever here even if there are many keys to * expire. So after a given amount of milliseconds return to the * caller waiting for the other active expire cycle. */ if ((iteration &amp; 0xf) == 0) &#123; /* check once every 16 iterations. */ elapsed = ustime()-start; if (elapsed &gt; timelimit) &#123; timelimit_exit = 1; server.stat_expired_time_cap_reached_count++; break; &#125; &#125; /* We don't repeat the cycle if there are less than 25% of keys * found expired in the current DB. */ &#125; while (expired &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4); &#125; ...&#125; 摘自itcast 数据逐出当内存不够时，删除哪些数据 有以下相关配置： 设置最大内存：maxmemory &lt;bytes&gt; 设置逐出策略：maxmemory-policy noeviction———&gt;默认 volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set. volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set. volatile-random -&gt; Remove a random key among the ones with an expire set. volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL) allkeys-lru -&gt; Evict any key using approximated LRU. allkeys-lfu -&gt; Evict any key using approximated LFU. allkeys-random -&gt; Remove a random key, any key. noeviction -&gt; Don&#39;t evict anything, just return an error on write operations. 设置抽样数目：maxmemory-samples 5 注意上述某些策略是approximated,主要就体现在抽样数量上，不是从所有的键中进行选择 lru means least recently used：简单理解就是按时间来说，最久没有使用的 lfu means least frequently used：简单说就是按次数来说，最少使用的 说是可以通过info stats中记录的keyspace_hits:1和keyspace_misses:2来调整策略 = =。]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis--事务]]></title>
    <url>%2F2020%2F02%2F25%2Fredis-5%2F</url>
    <content type="text"><![CDATA[事务：一个队列中，一次性，顺序性，排他性的执行一系列命令 基本操作 multi 开启事务，后面的指令暂时加入任务队列 exec 执行事务 discard 取消事务 注意 开启事务后，如果输入错误命令，不存在的指令，形式不对，则报错且关闭事务 开启事务后，如果语法格式正确，但操作类型错误，形式正确，执行事务时不会影响其他指令的运行，即不会回滚 锁 添加监视锁：watch key (check-and-set)乐观锁机制 一个客户端watch某个键后，不管其后的事务是否涉及到该键，只要其他客户端修改了该键，则本客户端的事务都会失败，返回(nil) 在事务中不能watch, 但是可以unwatch 取消监视的情况： 当exec被调用，无论事务是否成功执行，对所有键的监视都会取消 某客户端断开连接时，该客户端对键的监视也会取消 使用无参数指令unwatch取消该客户端对所有键的监视 分布式锁考虑一些问题： 保证锁总能释放掉 ——-&gt;设置失效时间 失效时间设置多久合适 ——–&gt; 延长锁机制，每隔1/3的失效时间进行检测，如果还在执行，则延迟锁时间 避免解掉别人的锁 ——-&gt;解锁时对随机标识串进行校验 如果不能保证redis总是可用的———&gt;Redlock算法，整多个redis，至少获取到N/2+1个redis的锁且未失效]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis--配置管理]]></title>
    <url>%2F2020%2F02%2F24%2Fredis-4%2F</url>
    <content type="text"><![CDATA[通过redis的配置文件更加深入的了解redis. 基础配置 port 6379 可以自定启动端口 daemonize yes 以守护进程的方式启动redis logfile &quot;&quot; 指定日志文件，如果为空，输出到标准输出 dir 指定工作目录，会将比如日志文件，数据库备份等存放在该目录下，需要先手动创建 持久化利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制称为持久化。 持久化的方式： 数据（快照）—–&gt; RDB 过程（日志）—–&gt; AOF RDB命令 ：save 手动执行一次保存操作 效果 ：在指定的dir目录下生成dump.rdb文件 注意 ：save指令的执行会阻塞当前redis服务器，线上环境不建议使用 命令 ：bgsave 异步执行快照操作 效果 ：调用fork()产生一个子进程完成具体的save操作，完成后给redis返回消息，可以在日志文件中查看 相关配置 rdbcompression yes 采用LZF压缩字符串对象 rdbchecksum yes redis5之后采用CRC64对数据文件进行校验，会影响10%左右的性能，如果关闭，数据末尾的校验数据会被设置为0，跳过验证 dbfilename dump.rdb 设置dump数据库生成的文件名 stop-writes-on-bgsave-error yes 持久化出现问题时是否停止备份 部分源码先只考虑没有冲突的情况（没有额外的saving/rewrite） 123456789101112131415161718192021222324/* If there is not a background saving/rewrite in progress check if * we have to save/rewrite now. */for (j = 0; j &lt; server.saveparamslen; j++) &#123; // 循环所有的 save seconds changes 配置 struct saveparam *sp = server.saveparams+j; /* Save if we reached the given amount of changes, * the given amount of seconds, and if the latest bgsave was * successful or if, in case of an error, at least * CONFIG_BGSAVE_RETRY_DELAY seconds already elapsed. */ if (server.dirty &gt;= sp-&gt;changes &amp;&amp; server.unixtime-server.lastsave &gt; sp-&gt;seconds &amp;&amp; (server.unixtime-server.lastbgsave_try &gt; CONFIG_BGSAVE_RETRY_DELAY || // 默认是5秒 server.lastbgsave_status == C_OK)) // 前边两个条件是 如果所作的修改大于指令指定次数并且距离上次保存时间也大于指定的时间 &#123; serverLog(LL_NOTICE,"%d changes in %d seconds. Saving...", sp-&gt;changes, (int)sp-&gt;seconds); rdbSaveInfo rsi, *rsiptr; rsiptr = rdbPopulateSaveInfo(&amp;rsi); rdbSaveBackground(server.rdb_filename,rsiptr); // 在这里边调用了fork创建子进程进行bgsave break; &#125;&#125; 如果操作没有error的话： 两次保存之间至少要间隔sp-&gt;seconds秒，即使到目前为止写的次数已经超过了sp-&gt;changes 经过sp-&gt;seconds秒并不会重置server.dirty已经写的次数 之前还在想如果设置的save 10 2，那么只要我不在10s内做两次写操作，那不就不会save了？ = =。 特殊启动形式 全量复制 服务器运行过程中重启 debug reload （在客户端运行指令，下同） 关闭服务器时指定保存数据 shutdown save 优点 能进行压缩，是一个紧凑的二进制文件，存储效率高 其数据是redis在某个时间点的快照，适合于数据备份，全量复制等场景 恢复速度比AOF快 用于灾难恢复 缺点 无法做到实时持久化，可能会丢失数据 bgsave由于需要创建子进程，会消耗一定的性能 多版本RDB文件格式可能不同意，有无法兼容的现象 AOFAppend only file持久化：以独立日志的方式记录每次写命令，重启时，重新执行AOF文件中的命令达到恢复数据的目的。能够解决数据持久化的实时性问题。 命令 appendonly yes/no appendfilename &quot;filename.aof&quot; appendfsync always/everysec/no 三种策略(appendfsync) no: don&#39;t fsync, just let the OS flush the data when it wants. Faster. always: fsync after every write to the append only log. Slow, Safest everysec: fsync only one time every second. Compromise. —————&gt;default 重写将redis进程内的数据转化为写命令同步到新AOF文件的过程。将对同一个数据的若干条命令执行结果转化为最终结果数据对应的指令进行记录，省去无效指令。 作用： 降低磁盘占用量 提高持久化效率 降低数据恢复用时 重写规则： 进程内已超时的数据不写 忽略无效指令，只保留最终数据的写入命令 对同一数据的多条写命令进行合并—————&gt;每条指令最多写64个元素 重写配置： auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb 涉及到的数据可以通过info persistence查看——-&gt; aof_current_size , aof_base_size 对比]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis--jedis]]></title>
    <url>%2F2020%2F02%2F24%2Fredis-3%2F</url>
    <content type="text"><![CDATA[在java项目中使用jedis对redis进行交互操作。 使用maven 使用maven命令构建项目： 12mvn archetype:generate -DgroupId=&#123;package&#125; -DartifactId=&#123;project&#125; -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 或者直接用IDE更方便。 导入Jedis依赖： 1234567&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; 直接使用12345678910111213141516@Testpublic void redisAdd() &#123; Jedis jedis = new Jedis("192.168.56.101", 6379); //string jedis.set("name", "theshy"); //hash jedis.hset("hash1", "name", "rookie"); //list jedis.lpush("list1", "jacklove"); //set jedis.sadd("set1", "ning", "baolan", "leyan"); //sorted_set jedis.zadd("zset1", 5.3, "first"); //close jedis.close();&#125;]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis--通用指令]]></title>
    <url>%2F2020%2F02%2F24%2Fredis-2%2F</url>
    <content type="text"><![CDATA[针对redis中的key的相关应用。 Key通用指令基础操作 EXISTS key [key ...] DEL key [key ...] TYPE key 时效性控制 EXPIRE key seconds PEXPIRE key milliseconds EXPIREAT key timestamp PEXPIREAT key milliseconds-timestamp TTL key 当key不存在(过期)返回-2 key未设置失效时间返回-1 PTTL key PERSIST key 查询模式 KEYS pattern 更多 help @generic 数据库通用指令基本操作 SELECT index PING [message] QUIT - ECHO message help @connection 数据移动 MOVE key db 数据清除 FLUSHDB FLUSHALL DBSIZE help @server]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis--基础数据]]></title>
    <url>%2F2020%2F02%2F23%2Fredis-1%2F</url>
    <content type="text"><![CDATA[各种数据类型的应用场景以及一些小问题。 string 单数据操作与多数据操作，考虑指令在应用服务器和Redis之间的传输消耗。set,mset redis用于控制数据库表主键id，为数据库表主键提供生成策略，保障数据库表主键的唯一性。incr redis用于控制数据的生命周期。setex,psetex 投票 redis用于各种结构型和非结构型高热度数据的加速访问。 分布式锁。setnx hash value字段只能存储字符串，不能套娃。 每个hash最多可存232-1个键值对. hash设计的初衷不是为了存储大量对象数据，不可滥用。 hgetall可能成为性能瓶颈。 redis用于抢购，限购，限量，激活码等业务的数据存储设计。 list 底层使用双向链表存储结构实现。 获取数据大多是从左操作的。lrange, lindex, llen 消息队列/任务队列。 blpop, brpop redis用于具有操作先后顺序的数据控制。点赞 list中存储的数据都是string类型，最多存232-1个。 redis实现最新消息的展示。 set 与hash存储结构完全相同，field即为值, value为空nil。 随机推送。 srandmember, spop redis用于同类信息的关联搜索，二度/深度关联搜索。sinter, sunion, sdiff 关注模型 redis用于同类型不重复数据的合并操作。权限验证 redis用于同类型数据的快速去重。统计访问量 redis基于黑白名单的服务控制。 sorted_set redis用于计数器组合排序功能对应的排名。 score数据的存储空间是64位的。 redis用于定时任务执行顺序管理或任务过期管理。 redis应用于及时任务/消息队列执行管理。 zrevrange]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.tar and .gz]]></title>
    <url>%2F2020%2F01%2F13%2Ftar-and-gz%2F</url>
    <content type="text"><![CDATA[在使用Linux时经常会涉及到文件的压缩与解压，这里对遇到的情况进行记录，后续继续补充。 tar应该是最常用的一个压缩/解压命令。这个命令可以用附加选项来支持解压其他后缀的文件。 tar -z可以解压涉及gzip, gunzip, ungzip的文件，比如xxxx.tar.gz tar -j可以解压涉及bzip2的文件，比如xxxx.tar.bz2，当然也可以先用unzip2把外面一层套脱了，再处理tar]]></content>
      <tags>
        <tag>linux</tag>
        <tag>tar</tag>
        <tag>bunzip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JNI in linux]]></title>
    <url>%2F2020%2F01%2F10%2Fjni-in-linux%2F</url>
    <content type="text"><![CDATA[在复习JVM时又看到了本地方法栈, 那么本地方法是个什么方法呢。JNI即java native interface, 通过这个东西可以实现在Java中调用其他编程语言实现的功能，在和系统底层交互时Java大都通过JNI调用C/C++来实现的。 下面用个实例来说明本地方法是如何实现的。 环境jdk-11.0.5: 在10之后就看不到javap这个命令了，这个命令的主要功能是根据java源码中声明的native方法，生成对应的c/c++头文件，其中的主要内容就是对native方法的声明。现在这个功能集成到了javac下，使用javac -h target_dic src_dic centos7: 在后续的编译过程中需要用到gcc, gcc-c++等包 具体实现1. java源码首先写一点简单的java源码，其中包含一native方法就行： 123456789101112public class HelloJni &#123; static &#123; System.loadLibrary("HelloJni"); &#125; public static native void sayHello(); public static void main(String args[]) &#123; sayHello(); &#125;&#125; 2. 生成头文件使用命令javac -h HelloJni.java, 得到的头文件如下： 123456789101112131415161718192021/* DO NOT EDIT THIS FILE - it is machine generated */#include "jni.h"/* Header for class HelloJni */#ifndef _Included_HelloJni#define _Included_HelloJni#ifdef __cplusplusextern "C" &#123;#endif/* * Class: HelloJni * Method: sayHello * Signature: ()V */JNIEXPORT void JNICALL Java_HelloJni_sayHello (JNIEnv *, jclass);#ifdef __cplusplus&#125;#endif#endif 可以看到这里自动生成的头文件中需要jni.h, 在jni.h中又需要jni_md.h。 3. C++实现对头文件中方法进行实现，我用的c++，不晓得头文件中的_cplusplus是不是在暗示用c++。 12345678#include "stdio.h"#include "HelloJni.h"JNIEXPORT void JNICALL Java_HelloJni_sayHello (JNIEnv *, jclass)&#123; printf("Hello World By Jni\n");&#125; 4. 编译我觉得比较绕的地方就是编译的过程了。 首先进行预处理，编译，汇编过程，不搞链接： 12gcc -I/root/jdk-11.0.5/include -I/root/jdk-11.0.5/include/linux -fPIC -c HelloJni.cpp -Idir: Add the directory dir to the list of directories to be searched for header files.前边提到的jni.h在include目录下，jni_md.h在目录include/linux目录下。 -fPIC: 当编译的时候不用这个指令的话，在后边生成动态库会出问题： /usr/bin/ld: HelloJni.o: relocation R_X86_64_32 against .rodata can not be used when making a shared object; recompile with -fPIC /usr/bin/ld: final link failed: Nonrepresentable section on output 编译好后得到HelloJni.o文件，做进一步处理： 1gcc -shared -o libHelloJni.so HelloJni.o 就能得到linux下动态链接库文件libHelloJni.so，这个文件在生成时需要规定其名字，由于在java代码中指定的加载库名为HelloJni，在生成链接库文件时需要命名为libHelloJni.so，否则会找不到库文件。 Exception in thread “main” java.lang.UnsatisfiedLinkError: no HelloJni in java.library.path: [/root/test, ., /usr/java/packages/lib, /usr/lib64, /lib64, /lib, /usr/lib] 5. 运行如果直接运行，还是会报错， Exception in thread &quot;main&quot; java.lang.UnsatisfiedLinkError: no HelloJni in java.library.path: [/usr/java/packages/lib, /usr/lib64, /lib64, /lib, /usr/lib] 会发现我们得到的链接文件不在后边的path中，可以选择把得到的链接文件拷一份，或者使用命令: 1export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH 把当前目录加到path中，这个变量应该是运行时生成的还是怎样，直接在linux中查看该变量啥也没有。 最后直接运行java代码，当然首先要javac。]]></content>
      <tags>
        <tag>JNI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PC in JVM]]></title>
    <url>%2F2019%2F12%2F28%2Fpc-in-jvm%2F</url>
    <content type="text"><![CDATA[PC(Program Counter Register): The Java Virtual Machine can support many threads of execution at once (JLS §17). Each Java Virtual Machine thread has its own pc (program counter) register. At any point, each Java Virtual Machine thread is executing the code of a single method, namely the current method (§2.6) for that thread. If that method is not native, the pc register contains the address of the Java Virtual Machine instruction currently being executed. If the method currently being executed by the thread is native, the value of the Java Virtual Machine’s pc register is undefined. The Java Virtual Machine’s pc register is wide enough to hold a returnAddress or a native pointer on the specific platform. 从上面的说明中可以提炼出一下几点信息： 程序计数器是线程私有的 程序计数器指向的是当前线程中正在被执行方法的地址(行号) 如果执行的本地方法，则计数器值为undefined 123456789101112131415161718192021222324252627282930313233public static int add(int, int); descriptor: (II)I flags: (0x0009) ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=2 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3 // String method add... 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: iload_0 9: iload_1 10: iadd 11: ireturnpublic static int sub(); descriptor: ()I flags: (0x0009) ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=0 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #5 // String method sub... 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: iconst_1 9: istore_0 10: iconst_2 11: istore_1 12: iload_0 13: iload_1 14: invokestatic #6 // Method add:(II)I 17: pop 18: iload_0 19: iload_1 20: isub 21: ireturn 如上代码段，可以简单理解PC中存储的是每条jvm指令开头的数字。 特定此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 参考 The Java® Virtual Machine Specification 周志明. (2014). 深入理解 Java 虚拟机一 JVM 高级特性与最佳实践.]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lambda in java and python]]></title>
    <url>%2F2019%2F12%2F28%2Flambda-in-java-and-python%2F</url>
    <content type="text"><![CDATA[Anonymous function: In computer programming, an anonymous function (function literal, lambda abstraction, or lambda expression) is a function definition that is not bound to an identifier. 可以简单的理解为去掉了标识符的匿名函数，下面记下自己用到的为数不多的地方= = using in java就我菜鸡而言，在java中Lambda主要在线程以及比较时见的多，比如下面新创建一个线程： 1234567new Thread(()-&gt;&#123; System.out.println("hello from: " + Thread.currentThread());&#125;).start();// output:// hello from: Thread[Thread-0,5,main] 或者实现一个自定义的比较: 12// Collections.sort(strings, (a, b) -&gt; b.length() - a.length());strings.sort((a, b) -&gt; b.length() - a.length()); using in python在python中，我主要在排序中用到，比如说按照key-value中的key或value来进行排序： 1234567# 按照value进行升序排序d = &#123;'a':1, 'g':3, 'd':2, 'c':0&#125;d = sorted(d.items(), key=lambda item:item[1])print(d)# output:# [('c', 0), ('a', 1), ('d', 2), ('g', 3)] 在map中作为映射使用： 123456l = [1,2,3,4,5]ll = list(map(lambda x:x*x, l))print(ll)# output:# [1, 4, 9, 16, 25]]]></content>
      <tags>
        <tag>lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[insert into a red-black tree]]></title>
    <url>%2F2019%2F12%2F24%2Finsert-into-a-red-black-tree%2F</url>
    <content type="text"><![CDATA[性质 每个节点是红的或黑的 根节点是黑的 所有的叶子节点(NIL)是黑的 红色节点的孩子只能是黑的 从任一节点到叶子节点所经过的黑色节点个数相同 就像这样: 插入不管是插入还是删除，只要能理出节点插入时其周围节点颜色的情况，就能对操作有个整体的认识。 还要注意的是，在插入时，把待处理的节点默认为红色会更方便，破坏的规则更少。 整体流程图： case1如果根节点为空，则待插入节点当作根节点，并设置为黑色。 case2如果父节点为黑色，那么插入一个红节点不会破坏任何性质，ok case3如果父节点为红色，这时候就需要考虑叔叔节点了，如果叔叔也是红色，那么就把父亲和叔叔变为黑色，爷爷变为红色，这样保持遍历该棵树时黑色节点数目不变，然后把爷爷当作待插入节点，递归处理。(因为在这里是爷爷，可能是别人的儿子) case4还是父节点为红，叔叔为黑色或没有，这时就需要旋转操作了，如果待插入节点和父亲节点在同一边，就绕着父亲节点做一次对应的旋转: 如果不在同一边，就需要先做一次旋转转到同一边，再继续。 删除删除的主要思想是用待删除节点的前继或后继节点替换该节点，再删除原前/后继节点，这里考虑用后继节点替换该待删除节点，(那么可知后继节点左孩子是叶子节点)，把后继节点的值copy到待删除节点上，然后只用考虑把后继节点删除就行了。因此后边的待删除节点都是☞原节点的后继节点了，不要搞错对象咯。 主要流程图： 自己为红那么它已经没得孩子了，直接删除就好。 右孩子为红把自己删了之后，用右孩子顶上，并改为黑色。 兄弟为红通过旋转往这边均个点改为黑的。 兄弟同边孩子为红 兄弟异边孩子为红 父亲为黑删除后把兄弟节点改为红的，这时候这个子树是没问题的，但是它作为更大的树的一部分，经过P的路径就会比原来少一个黑点，所以要再递归平衡P点。 父亲为红]]></content>
      <tags>
        <tag>红黑树</tag>
        <tag>RedBlackTree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mount disk automatically when start up]]></title>
    <url>%2F2019%2F11%2F29%2Fmount-disk-automatically-when-start-up%2F</url>
    <content type="text"><![CDATA[其实不用手动操作，deepin也会自动挂载磁盘，只不过它的路径看起来太长了。 主要分为3步: 创建挂载点 说白了就是从哪个路径访问到你的磁盘，这里边也有大学问，我不懂 查看磁盘的UUID 可以使用命令blkid，或者是lsblk --fs 编辑文件 /etc/fstab这个文件应该就是控制系统启动时所加载的磁盘，仿照上边规范的写法，加上自定的加载磁盘就好。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Levenshtein distance]]></title>
    <url>%2F2019%2F11%2F26%2Flevenshtein-distance%2F</url>
    <content type="text"><![CDATA[Levenshtein distance就是编辑距离，简单说就是将一个字符串A通过删除、插入、替换三种操作转化为字符串B，最少的操作数就称为编辑距离。可以通过DP实现编辑距离求解. Analysis假设我们现在要求字符串A的前i个字符转化为字符串B的前j个字符的最小操作数，如图1所示 图中的箭头表示这个状态矩阵填写的顺序，因此我们也已经有了T[i-1][j], T[i][j-1], T[i-1][j-1]等知识 那么能否利用这些已经计算的值，来计算T[i][j]呢? 在两个字符串都进行扩充时，新增加的字符有两种可能: A[i] == B[j] 这种情况比较好，说明当前新增的两个字符已经是匹配的，就不用再操他们的心了，此时T[i][j] = T[i-1][j-1] A[i] != B[j] 这时就不好办了，肯定要对字符串A进行三种操作中的一种才能得到字符串B，此时T[i][j] = min(三种操作) + 1 那么这个min(三种操作)怎么理解呢? T[i][j-1]表示前i个转化为前j-1个，然后A通过插入一个和B[j]一样的字符到i+1处，完成转化过程 T[i-1][j]表示前i-1个转化为前j个，然后通过删除A中第i个字符，完成转化过程 T[i-1][j-1]表示前i-1个转化为前j-1个，然后通过替换A中第i个字符为B中的第j个字符，完成转化过程 因此第二种情况下的转移方程可以写为T[i][j] = min(T[i][j-1], T[i-1][j], T[i-1][j-1]) + 1 Source12345678910111213141516171819202122232425262728293031323334353637def cal_dis(keyword1, keyword2): """ @keyword1: @keyword2: """ len1 = len(keyword1) len2 = len(keyword2) if len1 == 0: return len2 elif len2 == 0: return len1 # state matrix T = [[0 for i in range(len2+1)] for j in range(len1+1)] # initial T for i in range(len1): T[i][0] = i for j in range(len2): T[0][j] = j for i in range(len2): char1 = keyword2[i] for j in range(len1): char2 = keyword1[j] # case 1 if char1 == char2: T[j+1][i+1] = T[j][i] # case 2 else: T[j+1][i+1] = min(min(T[j-1][i], T[j][i-1]), T[j-1][i-1]) + 1 return T[len1][len2]if __name__ == '__main__': cal_ = cal_dis('kitten', 'sitting') print('cal =', cal_) Other感觉之前做了好一些关于字符串的题，大多是用DP求解的，自己还是太垃圾了，经常会混淆不同目的下的转移过程，唉。。。 比如说这一题，其目的是计算从A串到B串有多少种转移方式，哎。]]></content>
      <tags>
        <tag>dp</tag>
        <tag>编辑距离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Minhash]]></title>
    <url>%2F2019%2F11%2F25%2Fminhash%2F</url>
    <content type="text"><![CDATA[Minhash可以用来降维，其最重要的特点是，降维之后，数据之间的相似度可认为保持不变，要注意的是这里的相似度是用Jaccard计算的。 Stanford的课件讲的非常清楚。 最近真是越来越懒的，不想码字?]]></content>
      <tags>
        <tag>minhash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改Hexo中的分类名称]]></title>
    <url>%2F2019%2F09%2F10%2Fchange-categories-name%2F</url>
    <content type="text"><![CDATA[问题某天突然发现我的categories中英文名称首字母是小写的，所以想把它们改为首字母大写，但是在文章里边改了之后，页面中的类别确实是变了，但是点进去会出现404. 原因由于写好md后，是由hexo进行部署等工作生成public文件，即具体的页面，在此过程可能是由于git大小写不敏感的原因，导致categories名称只修改首字母大小写并不能产生新的分类，也就使得github上的public文件中包含的类别名称还是原来的样子，比如java，但是在具体的文章页面中该分类已经变成了Java，且对应的url也变更了，所以会出现访问404的问题. 解决通过手动修改github中public下的分类文件名称. 由于`git`大小写不敏感，所以无法直接修改： $ git mv haha Haha Rename from &apos;haha&apos; to &apos;Haha/haha&apos; failed. Should I try again? (y/n) n fatal: renaming &apos;haha&apos; failed: Permission denied 可以采用间接临时文件名作为中转就行了: $ git mv java/ temp/ $ git mv temp/ Java === 现在已经不用分类了，太麻烦了，直接用tag]]></content>
      <tags>
        <tag>git</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 124.Binary Tree Maximum Path Sum]]></title>
    <url>%2F2019%2F07%2F25%2FBinary-Tree-Maximum-Path-SUm%2F</url>
    <content type="text"><![CDATA[Question: Given a non-empty binary tree, find the maximum path sum. Example: Input: [-10,9,20,null,null,15,7] -10 / \ 9 20 / \ 15 7 Output: 42 Analysis: 因为是只用求最大路径长度，所以可以优先设置一个全局变量记录此最大长度。当遍历到某一点时，需要知道它左右各自最长的长度用作比较，所以这里选用后序遍历。在该点有三种路径，该点及左边、该点及右边、该点及两边；分别比较它们与全局最大长度比较，更新全局最大长度。 Answer: 1234567891011121314151617181920212223# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def maxPathSum(self, root: TreeNode) -&gt; int: if not root: return 0 maxS = -sys.maxsize def helper(root): nonlocal maxS if not root: return 0 maxl = helper(root.left) maxr = helper(root.right) oneSide = max(maxl, maxr, 0) + root.val connect = maxl+maxr+root.val maxS = max(maxS, oneSide, connect) return oneSide helper(root) return maxS]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 115.Distinct Subsequences]]></title>
    <url>%2F2019%2F07%2F25%2FDistinct-Subsequences%2F</url>
    <content type="text"><![CDATA[Question: Given a string S and a string T, count the number of distinct subsequences of S which equals T. Example: Input: S = &quot;rabbbit&quot;, T = &quot;rabbit&quot; Output: 3 Explanation: As shown below, there are 3 ways you can generate &quot;rabbit&quot; from S. (The caret symbol ^ means the chosen letters) rabbbit ^^^^ ^^ rabbbit ^^ ^^^^ rabbbit ^^^ ^^^ Analysis: 动态规划，dp[i][j]表示前i个S串能组成前j个T串的字串个数。 如果S[i] == T[j]，那么dp[i][j]就有两种组成字串的可能，一种是由于S[i]和T[j]相同，直接用S[i-1]和T[j-1]组成的字串在分别加上S[i]和T[j]；另一种是直接把S[i]删掉不考虑。 因此dp[i][j] = dp[i-1][j-1] + dp[i-1][j] 当S[i] != T[j]，直接把S[i]删掉不考虑， 因此dp[i][j] = dp[i-1][j] Answer: 123456789101112131415161718192021222324252627282930class Solution(object): def numDistinct(self, s, t): """ :type s: str :type t: str :rtype: int """ # dp lens = len(s) lent = len(t) if lens &lt; lent: return 0 if lent == 0: return 1 if lens == 0: return 0 dp = [[0 for i in range(lent+1)] for j in range(lens+1)] # init dp[0][0] = 1 for i in range(1, lens+1): dp[i][0] = 1 for j in range(1, lent+1): dp[0][j] = 0 for i in range(1, lens+1): for j in range(1, lent+1): if t[j-1] == s[i-1]: dp[i][j] = dp[i-1][j-1] + dp[i-1][j] else: dp[i][j] = dp[i-1][j] return dp[lens][lent]]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 97.Interleaving_String]]></title>
    <url>%2F2019%2F07%2F13%2FInterleaving-String%2F</url>
    <content type="text"><![CDATA[Question: Given s1, s2, s3, find whether s3 is formed by the interleaving of s1 and s2. Example: Input: s1 = &quot;aabcc&quot;, s2 = &quot;dbbca&quot;, s3 = &quot;aadbbcbcac&quot; Output: true Analysis: 刚开始的想法是回溯，用三个游标分别记录当前字符串遍历到的字符，当s1和s2中只有一个字符和s3相同，那么该字符串和s3的游标移动到下一个，这是比较好处理的情况；另一种情况s1、s2、s3的当前游标字符都相同，这时候是用s1的还是s2的呢，我把当前三个游标的位置记录下来，先默认使用s1的，当后续出现不匹配的情况时，选择和当前判断最近的这种情况，在用s2进行处理。当然最后超时了。 比较好的方法就是动态规划了，dp[i][j]表示s1串前i个字符和s2串前j个字符能否组成s3串前i+j个字符，其核心规律为: dp[i][j] = (dp[i-1][j] and s1[i] == s3[i+j-1]) or (dp[i][j-1] and s2[j] == s3[i+j-1]) Answer: 1234567891011121314151617181920212223242526272829class Solution(object): def isInterleave(self, s1, s2, s3): """ :type s1: str :type s2: str :type s3: str :rtype: bool """ # dp[i][j] 前i个s1和前j个s2能否组成前i+j个s3 len1 = len(s1) len2 = len(s2) len3 = len(s3) if len1 + len2 != len3: return False dp = [[False for j in range(len2+1)] for i in range(len1+1)] dp[0][0] = True # j = 0 for i in range(len1): if dp[i][0] and s1[i] == s3[i]: dp[i+1][0] = True # i = 0 for j in range(len2): if dp[0][j] and s2[j] == s3[j]: dp[0][j+1] = True for i in range(1, len1+1): for j in range(1, len2+1): dp[i][j] = (dp[i-1][j] and s1[i-1] == s3[i+j-1]) or (dp[i][j-1] and s2[j-1] == s3[j+i-1]) return dp[len1][len2]]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 95.Unique Binary Search Trees II]]></title>
    <url>%2F2019%2F07%2F06%2FUnique-Binary-Search-Trees%2F</url>
    <content type="text"><![CDATA[Question: Given an integer n, generate all structurally unique BST’s (binary search trees) that store values 1 … n. Example: Input: 3 Output: [ [1,null,3,2], [3,2,null,1], [3,1,null,null,2], [2,1,3], [1,null,2,null,3] ] Explanation: The above output corresponds to the 5 unique BST&apos;s shown below: 1 3 3 2 1 \ / / / \ \ 3 2 1 1 3 2 / / \ \ 2 1 2 3 Analysis: 二叉搜索树，其任一节点的左子树都小于该节点，右子树都大于该节点。由于节点的值从1到n，所以可以考虑将每个值都当做根节点，然后该值左边的放在左边，右边的放右边，比如5作为根节点时，1~4就作为左子树，5~n作为右子树。 Answer: 123456789101112131415161718192021222324252627282930313233343536373839404142434445# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def generateTrees(self, n): """ :type n: int :rtype: List[TreeNode] """ if n == 0: return None if n == 1: root = TreeNode(1) return [root] return self.helper(1, n) def helper(self, start, end): res = [] # only one node if start == end: s = TreeNode(start) res.append(s) return res # 由于i是从start开始的，在第一轮递归时，其范围为(start, i-1)，这时候会有start &gt; end # 比如说是1~3，在1作为根节点时，其左子树为None，因此这里是这样处理的 if start &gt; end: res.append(None) return res # make i as the root node for i in range(start, end + 1): left = self.helper(start, i - 1) right = self.helper(i + 1, end) # combine each left and right for le in left: for ri in right: root = TreeNode(i) root.left = le root.right = ri res.append(root) return res]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 91.Decode ways]]></title>
    <url>%2F2019%2F07%2F03%2Fdecode-ways%2F</url>
    <content type="text"><![CDATA[Question A message containing letters from A-Z is being encoded to numbers using the following mapping: ‘A’ -&gt; ‘1’‘B’ -&gt; ‘2’…‘Z’ -&gt; ‘26’ Given a non-empty string containing only digits, determine the total number of ways to decode it. Analysis:刚开始想的是把字符串中不用分开的保留出来，比如’12134621’可以分成’1213|4|6|21’，然后把’1213’和’21’能分的种数相乘，现在的问题就是考虑’1213’和’21’有多少分法。这其实也是一种斐波拉契数列，例如: f(&apos;1&apos;) = 1 f(&apos;12&apos;) = 2 f(&apos;121&apos;) = f(&apos;12|1&apos;) + f(&apos;1|21&apos;) = f(&apos;12&apos;) + f(&apos;1&apos;) ... f(n) = f(n-1) + f(n-2) 另一种解法，直接遍历字符串，根据上述公式进行计算，感觉更加简洁明了。 Answer: 12345678910111213141516171819202122232425262728class Solution(object): def numDecodings(self, s): """ :type s: str :rtype: int """ # 当前n个字符分好后，n+1个字符长度有dp[n]+dp[n-1] # 比如 '12212' = '122'|'12' + '1221'|'2' # 当然要注意能分开的条件 if len(s) == 0 or s[0] == '0': return 0 if len(s) == 1: return 1 length = len(s) # dp[i]表示前i个字符可分的方法数 dp = [0 for i in range(length+1)] dp[0] = 1 for i in range(length): # 先假设'0'不能和前边的划分在一起, 那么这个'0'是无法处理的 if s[i] == '0': dp[i+1] = 0 # 把s[i]单独划分 else: dp[i+1] = dp[i] # 把s[i]和s[i-1]分一起 if i &gt; 0 and s[i-1] == '1' or (s[i-1] == '2' and s[i] &lt; '7'): dp[i+1] += dp[i-1] return dp[length]]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 85.Maximal Rectangle]]></title>
    <url>%2F2019%2F06%2F21%2FMaximal-Rectangle%2F</url>
    <content type="text"><![CDATA[Question: Given a 2D binary matrix filled with 0’s and 1’s, find the largest rectangle containing only 1’s and return its area. Example: Input: [ [“1”,”0”,”1”,”0”,”0”], [“1”,”0”,”1”,”1”,”1”], [“1”,”1”,”1”,”1”,”1”], [“1”,”0”,”0”,”1”,”0”] ] Output: 6 Analysis: 除了循环使用单调栈的方法，看到了一种很有趣的方法，即采用二进制运算。根据多行数据之间的&amp;运算计算高度，同行数据和移位后数据的&amp;运算计算宽度。但是这种方法需要对输入数据做预处理，将字符数组转化为二进制数。 Answer: 12345678910111213141516# 假设数据处理后 datas = &#123;10100, 10111, 11111, 10010&#125;for i in range(4): temp = data[i] for j in range(i, 4): temp = temp &amp; data[j] if temp is none: break height = j - i + 1 move = temp width = 0 while move != 0: width = width + 1 move = move &amp; move &gt; 1 if height * width &gt; max: max = height * width]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>二进制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 84. Largest Rectangle in Histogram]]></title>
    <url>%2F2019%2F05%2F18%2FLargest-Rectangle-in-Histogram%2F</url>
    <content type="text"><![CDATA[Question: Given n non-negative integers representing the histogram’s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram. Analysis: 暴力循环是可以求出来，但是超时。通过观察可以发现，最大的面积一般不是由最高的柱决定，但是往往都会把它包含起来。所以，在找最大面积时，可以在找到了一个顶点时，再往前扫描计算面积。拿示例来说，0位置的2是一个顶点，计算面积；往后到了3位置的6又是一个顶点，往前扫描分别得到6， 10等。如此一来，就避免了很多无谓的计算。由于是在找到顶点时再计算面积，所以需要保存前面的值来判断哪个值是顶点，使用单调递增栈这一数据结构可以保存这些信息。单调递增栈，首先是个栈，其次保存的数据是递增的，当入栈的值小于栈顶时，对栈顶元素做出栈操作，直到当前值可以作为栈顶元素。 Answer: 12345678910111213141516171819202122232425262728293031323334class Solution &#123; public int largestRectangleArea(int[] heights) &#123; // 保存最大的长方形 int maxR = 0; // 取出的栈顶 int nowH = 0; //单调递增栈 ArrayDeque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); // 这里循环到 heights.length for (int i = 0; i &lt;= heights.length; i ++) &#123; if ((stack.isEmpty()) || (i &lt; heights.length &amp;&amp; heights[stack.peekLast()] &lt;= heights[i])) &#123; // 栈里边放的是位置，便于计算宽 stack.offerLast(i); &#125; else &#123; // 取出的栈顶当做当前矩形的高 nowH = stack.pollLast(); // 1. 由于栈中是递增顺序的，取出栈顶nowH后，栈如果为空且nowH前边原本是有元素的，说明nowH比前边的都要小，也就是以[nowH]为高时可以 // 把前边的也包含住，所以宽为 i // 2. 如果取出nowH后，栈不为空，根据相应位置计算宽 maxR = Math.max(maxR, heights[nowH]*(stack.isEmpty()? i: (i - 1 - stack.peekLast()))); i --; &#125; &#125; return maxR; &#125;&#125;]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>单调栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 76. Minimum Window Substring]]></title>
    <url>%2F2019%2F04%2F25%2FMinimum-Window-Substring%2F</url>
    <content type="text"><![CDATA[Question: Given a string S and a string T, find the minimum window in S which will contain all the characters in T in complexity O(n). Analysis: 在S串中找到一个子串，包含T中所有的字符。可以通过滑动窗口来求解，所谓的窗口在这就可以理解为S的子串。利用数组分别保存窗口中各个字符的个数和T串中字符的个数，同时设置一个计数器，用来统计窗口中的符合T串的字符的个数。那么如何判断哪些字符是在T串中的呢，只需要判断在窗口中该字符出现的次数是否小于T串中该字符出现的次数就好了。 Answer: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class Solution &#123; public String minWindow(String s, String t) &#123; // 在s中找一个子串，包含t中所有的字符 if (s.length() &lt; t.length()) &#123; return ""; &#125; int lenS = s.length(); int lenT = t.length(); int[] sFre = new int[58]; int[] tFre = new int[58]; // 窗口边界 int l = 0; int r = 0; // 记录最小窗口 int start = -1; int end = lenS + 1; // 记录当前窗口匹配的字符个数 int count = 0; for (int i = 0; i &lt; lenT; i ++) &#123; tFre[t.charAt(i) - 'A'] ++; &#125; // 比如 s="adceba" t="abc", 那么 l &lt;= 3, 如果l超过3,后边所有字符长度也不够t的长度了 while (l &lt;= lenS - lenT) &#123; // 窗口右标没有越界, 并且还没有把t串完全包含 if (r &lt; lenS &amp;&amp; count &lt; lenT) &#123; char temp = s.charAt(r); sFre[temp - 'A'] ++; // 当s频率小于t中的频率, 说明该字符包含在t中 if (sFre[temp - 'A'] &lt;= tFre[temp - 'A']) &#123; count ++; &#125; r ++; &#125; else if (count &gt;= lenT) &#123; char temp = s.charAt(l); if (r - l &lt; end - start) &#123; start = l; end = r; &#125; if (sFre[temp - 'A'] &lt;= tFre[temp - 'A']) &#123; count --; &#125; sFre[temp - 'A'] --; l ++; &#125; else &#123; break; &#125; &#125; return start == -1? "": s.substring(start, end); &#125;&#125;]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>substring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 60. Permutation Sequence]]></title>
    <url>%2F2019%2F04%2F11%2Fpermutation-sequence%2F</url>
    <content type="text"><![CDATA[Question: The set [1,2,3,…,n] contains a total of n! unique permutations.By listing and labeling all of the permutations in order, we get the following sequence for n = 3:1.”123”2.”132”3.”213”4.”231”5.”312”6.”321”Given n(1~9) and k, return the kth permutation sequence. Analysis: 通过观察示例我们会发现，当n=3时，第一位上每个数字重复的个数为2，这个重复的个数其实是由后边几位有多少种排列方式决定的。比如当n=4时，第一位上的重复的个数是由后边3位全拍列个数决定的，那就是第一位上会重复6次。也就是说，所有的全拍列已经被各个位上相同的数字分好了组，通过这种方式，我们可以从第一位开始，只用循环判断n次就能找到指定位置的排列组合。 Answer: 123456789101112131415161718class Solution &#123; public String getPermutation(int n, int k) &#123; List&lt;Integer&gt; nums = new ArrayList&lt;&gt;(); int[] fac=&#123;1, 1, 2, 6, 24, 120, 720, 5040, 40320&#125;; for (int i = 0; i &lt; n; i ++) &#123; nums.add(i+1); &#125; String res = ""; k--; int index = 0; for (int i = n - 1; i &gt;= 0; i --) &#123; index = k / fac[i]; res += nums.remove(index); k = k % fac[i]; &#125; return res; &#125;&#125; More: 这里的k为什么要提前减1呢? 举个例子，当n=3时，比如说我们要求第二个，此时k=2。 如果我们不把k减1，得到的index为1，余数为0，那么按照123来取，第一位取到的就是2了。进一步归纳一下，如果k不减1，当余数为0时，其实是上一组（index-1）的最后一个。这样就会使得处理起来不那么方便。 如果我们把k减1，就是把全拍列的组合是从0开始计数的。按照上边的例子，此时index为0，余数为1，也就是第1组的第二个，要知道我们存储nums的数组也是从0开始计算的，这样就不用考虑当余数为0时是index还是index-1的问题，可以统一处理，比较方便。]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 51. N-Queens I]]></title>
    <url>%2F2019%2F03%2F30%2Fn-queens%2F</url>
    <content type="text"><![CDATA[Question: The n-queens puzzle is the problem of placing n queens on an n×n chessboard such that no two queens attack each other.Given an integer n, return the number of distinct solutions to the n-queens puzzle. Analysis: 皇后问题是一个比较经典的递归回溯类的问题，一般思路就是从第一排第一列开始放，判断是否会冲突，如果可以放就递归到下一排第一列继续放，否则就到下一列，如果这一列都不行，就回溯到上一排的下一列。 Answer: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123; public List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; // List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;&gt;(); // 数组下标表示行, 值表示列 int[] pos = new int[n]; // 初始化 for (int i = 0; i &lt; n; i ++) &#123; pos[i] = -1; &#125; dfs(pos, 0, 0); return res; &#125; public void dfs(int[] pos, int row, int line) &#123; // 跳出条件, pos[n-1] != -1 if (row &gt;= pos.length) &#123; List&lt;String&gt; temp = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; pos.length; i ++) &#123; StringBuilder sb = new StringBuilder(); for (int j = 0; j &lt; pos.length; j ++) &#123; if (j != pos[i]) &#123; sb.append("."); &#125; else &#123; sb.append("Q"); &#125; &#125; System.out.println(sb.toString()); temp.add(sb.toString()); &#125; res.add(temp); &#125; else &#123; for (int j = line; j &lt; pos.length; j ++) &#123; if (isValid(pos, row, j)) &#123; pos[row] = j; dfs(pos, row+1, 0); pos[row] = -1; &#125; &#125; &#125; &#125; public boolean isValid(int[] pos, int row, int line) &#123; for (int i = 0; i &lt; row; i ++) &#123; if (pos[i] == line &amp;&amp; pos[i] != -1) &#123; return false; &#125; if (((row-i) == (line-pos[i])) || ((i-row) == (line-pos[i]))) &#123; return false; &#125; &#125; return true; &#125;&#125; More: 这种递归回溯的效率还是比较低的，我认为主要耗时的操作就是判断当前摆放的皇后是否会和前排摆好的皇后产生冲突，在看了别人的解答后，学到了一种快速判断的方法。 这种方法非常巧妙，利用了棋盘(二维数组)坐标的特点，例如下边分别把各个点的横纵坐标进行相加和相减: 横 纵 相 加 0 1 2 3 1 2 3 4 2 3 4 5 3 4 5 6 横 纵 相 减 0 1 2 3 -1 0 1 2 -2 -1 0 1 -3 -2 -1 0 可以发现相加后值相等的都在同一左斜对角线，相减则相反，利用这一特性，可以快速判断皇后们是不是在对角线上!!!]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 44. Wildcard Matching]]></title>
    <url>%2F2019%2F03%2F27%2FWildcard-Matching%2F</url>
    <content type="text"><![CDATA[Question: Given an input string (s) and a pattern (p), implement wildcard pattern matching with support for ‘?’ and ‘*’. 12&apos;?&apos; Matches any single character.&apos;*&apos; Matches any sequence of characters (including the empty sequence). Analysis: *可以匹配任意内容包括空字符串，所以这个*要匹配多少就是最根本的问题。 Answer: 动态规划 12345678910111213141516171819202122232425262728293031323334class Solution &#123; public boolean isMatch(String s, String p) &#123; // value[i][j] 表示前i个模式串字符 和 前j个匹配串是否匹配 boolean value[][] = new boolean[p.length()+1][s.length()+1]; value[0][0] = true; // 初始化 for (int j = 1; j &lt;= s.length(); j ++) &#123; value[0][j] = false; &#125; // 遍历模式串进行匹配 for (int i = 1; i &lt;= p.length(); i ++) &#123; char temp = p.charAt(i-1); if (temp == '*') &#123; value[i][0] = value[i - 1][0]; for (int j = 1; j &lt;= s.length(); j ++) &#123; value[i][j] = value[i - 1][j] || value[i][j - 1] || value[i - 1][j - 1]; &#125; &#125; else if (temp == '?') &#123; value[i][0] = false; for (int j = 1; j &lt;= s.length(); j ++) &#123; value[i][j] = value[i - 1][j - 1]; &#125; &#125; else &#123; value[i][0] = false; for (int j = 1; j &lt;= s.length(); j ++) &#123; value[i][j] = (value[i - 1][j - 1]) &amp;&amp; (p.charAt(i - 1) == s.charAt(j - 1)); &#125; &#125; &#125; return value[p.length()][s.length()]; &#125;&#125; 双指针 通过指针记录*匹配的位置. 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; public boolean isMatch(String s, String p) &#123; int sp = 0; int pp = 0; int pstar_idx = -1; int sstar_idx = -1; boolean res = false; while (sp &lt; s.length()) &#123; if (pp &lt; p.length() &amp;&amp; (s.charAt(sp) == p.charAt(pp) || p.charAt(pp) == '?')) &#123; sp ++; pp ++; &#125; else if (pp &lt; p.length() &amp;&amp; p.charAt(pp) == '*') &#123; pstar_idx = pp; sstar_idx = sp; pp ++; &#125; // 记录'*'的位置，当后面不匹配时，就把不匹配的字符归到'*'里，从下一个在进行匹配操作 else if (pstar_idx != -1) &#123; pp = pstar_idx + 1; sp = ++ sstar_idx; &#125; else &#123; break; &#125; &#125; while (pp &lt; p.length() &amp;&amp; (p.charAt(pp) == '*')) &#123; pp ++; &#125; if (pp == p.length() &amp;&amp; sp == s.length()) &#123; res = true; &#125; return res; &#125;&#125; 当模式串中有多个*时，只会保存最新遇到的*，这样做可行吗，举个例子: s:abcdabcd p:ab*da*d 这个模式串的格式为ab...da...d, 当模式串匹配到第二个*时，说明前面的ab*da都已经匹配到了，那么就不用再考虑了，也就只用记录最新碰到的*.]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>通配符匹配</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 50. Pow(x, n)]]></title>
    <url>%2F2019%2F03%2F27%2Fleetcode50%2F</url>
    <content type="text"><![CDATA[Question: Implement pow(x, n), which calculates x raised to the power n (xn). Analysis: 首先观察幂的格式，例如： 1005 = 100(0101)2 = 100(0100)2 * 100(0001)2 这样一来，我们只用从低位到高位遍历一遍指数的大小，就能计算出结果. Answer: 123456789101112131415161718class Solution &#123; public double myPow(double x, int n) &#123; double res = 1; long a = n; a = Math.abs(a); while (a != 0) &#123; if ((a &amp; 1) == 0) &#123; x = x * x; &#125; else &#123; res *= x; x = x * x; &#125; a = a &gt;&gt; 1; &#125; return n &gt; 0 ? res : 1 / res; &#125;&#125; 注意: 把指数从int转化为long类型是由于这里指数的范围是[-231, 231-1]，当指数为负数时，处理方法是按指数绝对值计算最后结果求倒数，如果不转化为long类型，当指数值为-231时，取其绝对值就会超过int类型范围. 在判断指数各个位的值时，要注意 &amp;/== 的优先级关系，因此这里与操作需要加括号.]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>二进制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7开放防火墙端口]]></title>
    <url>%2F2018%2F09%2F17%2Fopen-firewall-in-centos7%2F</url>
    <content type="text"><![CDATA[Centos7之前一般是用iptables管理防火墙相关内容的，一般用到的就是开放一个端口供我们的应用使用，其命令如下:iptables -I INPUT -p tcp --dport 11111 -j ACCEPT 添加端口: 删除端口: Centos7一般新增了firewall-cmd，用来管理防火墙首先开启systemctl start firewalld 查看状态firewall-cmd --state 添加端口firewall-cmd --add-port=11111/tcp --zone=public --permanent 查看端口firewall-cmd --list-ports 添加端口后一般是用 firewall-cmd --reload来更新使其生效 firewall中的zone，不知道和iptables中的chain有没有关系，用firewall-cmd添加的端口在iptables -L -n中也可以看到(好像是废话- -) 删除端口firewall-cmd --remove-port=11111/tcp 基本的使用over.]]></content>
      <tags>
        <tag>linux</tag>
        <tag>firewall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Huffman Code]]></title>
    <url>%2F2018%2F09%2F17%2Fhuffman-code%2F</url>
    <content type="text"><![CDATA[前两天做笔试题时碰到了久违的哈夫曼编码, 想当初还用c实现过了, 但是做题的时候突然就忘了哈夫曼的实现过程- -，下面记录一下具体的步骤。 过程 计算各个待编码字符出现的频率. 比如HELLOWORLD，一共10个字符，H E W R D各1次，L3次，O2次，各自出现的频率就是次数/总数。 在频率中找最小的两个值，相加，结果放进频率集中。这样做的目的是，频率越小，说明出现的次数相对越少，那么在进行Huffman编码时，这些小频率的字符就在Huffman树的底层，则生成的编码就越长，相对的，频率高的就出现在Huffman树的高层，生成的编码越短，这样就可能起到压缩的效果。例如当前的频率集为0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.3，选取两个0.1进行操作，新的频率集为0.1, 0.1, 0.1, 0.2, 0.2, 0.3。 构造Huffman树: 重复第二步直到构造出完整的Huffman树，接下来就是编码了，很简单，左右子树分别标记为0/1，如下图:每个字符的编码就是从根节点到该节点路径上的标识，比如W为000，H为1010。 总结流程大概就是这样，从图中也可以看出来，Huffman编码是一种前缀编码，即每个编码不会是另外编码的前缀，因为每个字符都是叶子节点，如果有一个编码是其他编码的前缀，那么该编码的字符一定不是叶子节点。]]></content>
      <tags>
        <tag>huffman</tag>
        <tag>哈夫曼</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的流]]></title>
    <url>%2F2018%2F09%2F12%2Fstream-in-java%2F</url>
    <content type="text"><![CDATA[Java类库中的I/O类分成输入和输出两部分, 可以在JDK文档的类层次结构中看到。通过继承, 任何自InputStream和Reader派生而来的类都含有名为read的基本方法, 用于读取单个字节或字节数组。同样, 任何继承自OutputStream和Writer而来的类都含有名为write的基本方法, 用于写单个字节或字节数组。我们很少使用单一的类来创建流对象, 而是通过叠合多个对象来提供所期望的功能, 也就是类外套上其他的类, 即装饰器设计模式。 InputStreamInputStream的作用是用来表示那些从不同数据源产生输入的类。这些数据源包括但不限于: 字节数组 String对象 文件 管道, 工作方式和实际管道类似, 从一端输入, 从另一端输出 这些数据源都有对应的InputStream子类, 一般称为介质流: ByteArrayInputStream StringBufferInputStream(Deprecated) FileInputStream PipedInputStream 可以把以上输入流归为介质流, 因为这些流是和具体的源数据打交道的。另外, FilterInputStream也是一种输入流, 只不过它是套在介质流之外的, 可以称作包装流/过滤流, 主要有以下几种: BufferedInputStream DataInputStream PushbackInputStream OutputStream和InputStream对应, OutputStream流中的介质流也主要有以下几种: ByteArrayOutputStream FileOutputStream PipedOutputStream 包装流/过滤流主要有: BufferedOutputStream DataOutputStream PrintStream other如何按照指定编码读取文件? 读取文件一般就想到用FileInputStream, 但是我们看下它的构造方法, 并没有提供”编码”这项功能, 其实基本上字节流都没有指定编码这项功能, 在一番查找下, 才最终在InputStreamReader中找到了charset 12345678910111213141516171819202122public InputStreamReader(InputStream in, String charsetName) throws UnsupportedEncodingException&#123; super(in); if (charsetName == null) throw new NullPointerException("charsetName"); sd = StreamDecoder.forInputStreamReader(in, this, charsetName);&#125;public InputStreamReader(InputStream in, Charset cs) &#123; super(in); if (cs == null) throw new NullPointerException("charset"); sd = StreamDecoder.forInputStreamReader(in, this, cs);&#125;public InputStreamReader(InputStream in, CharsetDecoder dec) &#123; super(in); if (dec == null) throw new NullPointerException("charset decoder"); sd = StreamDecoder.forInputStreamReader(in, this, dec);&#125; 说到编码, 其实String类的构造函数中也提供了指定编码的功能: 123456public String(byte bytes[], int offset, int length, Charset charset) &#123; if (charset == null) throw new NullPointerException("charset"); checkBounds(bytes, offset, length); this.value = StringCoding.decode(charset, bytes, offset, length);&#125; InputStreamReader和OutputStreamWriter是连接字节流和字符流的桥梁:InputStreamReader用指定的编码或者默认平台编码从字节中读取数据并把他们解码为字符OutputStreamWriter用指定的编码或默认平台编码把写入的字符编码为相应的字节 如何采用”追加”方式向文件中写东西?这个平时还真没注意, 但是在c或python我还记得是以a方式打开文件, 然后翻了FileOutputStream发现java中并没有所谓的”方式”, 在write方法中会隐藏一个append字段: 123456789101112public void write(byte b[]) throws IOException &#123; writeBytes(b, 0, b.length, append);&#125;public void write(byte b[], int off, int len) throws IOException &#123; writeBytes(b, off, len, append);&#125;private native void writeBytes(byte b[], int off, int len, boolean append) throws IOException;...... 那么这个字段值是在哪指定的呢? 再看它的构造函数: 123public FileOutputStream(File file, boolean append)&#123;&#125;public FileOutputStream(String name, boolean append)&#123;&#125; 在构造文件输出流时就会让你选择是否以追加的模式构建流.]]></content>
      <tags>
        <tag>io</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dijkstra-单源最短路径问题]]></title>
    <url>%2F2018%2F09%2F08%2Fdijkstra%2F</url>
    <content type="text"><![CDATA[关于图论中的算法大多还是数据结构课上讲的, 过了这么久突然想起来, 就来复习复习吧。这里看一下Dijkstra算法再有向图中的使用。具体的需求就是给定一个图和一个点, 求出从该点出发到各个点的最短距离。下边放一张从wiki拿来的图: 不过这张是无向图, 但是大致的流程是类似的。 下面通过一个更具体是示例来说明, 我们的图如下所示: 需求: 从1开始, 到各个点的最短距离准备: 我们可以利用三个数组存储相关的信息 sign[] 记录已经被访问过的点 shortest[] 保存当前点到1的最短距离 precursor[] 记录1到当前点的路径中, 当前点的前驱点 初始化:根据图将三个数组分别初始化为, 规定-1为无穷远sign[] 1, 0, 0, 0, 0shortest[] -1, 3, -1, -1, 30precursor[] 1, 1, 1, 1, 1 过程: 找到距离1最短的点, 一看是2, 距离为3, 把2标记为访问过的, 更新sign数组; 然后从2找没标记过的点x, 看2到x的距离加上0到2的距离是否小于0到x的距离, 如果小于的话, 就更新shortest数组; 把x的前缀改为2, 更新precursor数组。 经过这些操作后, 三个数组变成这样了: sign[] 1, 1, 0, 0, 0shortest[] -1, 3, 28, 11, 30precursor[] 1, 1, 2, 2, 1 接下来最短距离是11, 为4, 再从4开始重复上述步骤: sign[] 1, 1, 0, 1, 0shortest[] -1, 3, 15, 11, 23precursor[] 1, 1, 4, 2, 4 直到所有的点都标记为访问过的, 最终结果为: sign[] 1, 1, 1, 1, 1shortest[] -1, 3, 15, 11, 23precursor[] 1, 1, 4, 2, 4 根据这些记录我们可以得出1到各个点的最短距离以及路径:1-&gt;2 3 1-&gt;21-&gt;3 15 1-&gt;2-&gt;4-&gt;31-&gt;4 11 1-&gt;2-&gt;41-&gt;5 23 1-&gt;2-&gt;4-&gt;5 这里说一下路径的计算过程, 以1-&gt;3为例, 根据precursor记录的前驱, 我们看到3的前驱是precursor[3]=4, 即4-&gt;3, 4的前驱precursor[4]=2, 即2-&gt;4-&gt;3, 再看2的前驱precursor[2]=1, 即1-&gt;2-&gt;4-&gt;3, 这样就求出了完整的路径。 下面贴份code, 写的不好看请原谅- -: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package graph;import java.util.Scanner;/** * Dijstra 算法 有向图，有权值，求一个点到各个点的最短距离 * */public class Dijkstra &#123; private static Scanner s = new Scanner(System.in); /** * 输入图 * @param n 点的个数 * @param k 边的个数 * @param a 保存图的信息 */ private static void input(int n, int k, int[][] a) &#123; for (int i = 0; i &lt; n; i ++) &#123; for (int j = 0; j &lt; n; j ++) &#123; // 初始化 a[i][j] = -1; &#125; &#125; for (int i = 0; i &lt; k; i ++) &#123; int start = s.nextInt(); int end = s.nextInt(); int value = s.nextInt(); a[start][end] = value; &#125; &#125; private static void printEdges(int[][] a) &#123; for (int i = 0; i &lt; a.length; i ++) &#123; for (int j = 0; j &lt; a.length; j ++) &#123; System.out.print(a[i][j] + " "); &#125; System.out.println(); &#125; &#125; /** * 基本思路: * 1. 从0开始, 找到最短的一条边, 假设为k点, 即0-k最短 * 2. 从k点开始, 找k到各个点的距离, 如果比0到它更短, 则更新最短距离, 并且更新前驱节点 * * @param a 图 */ private static void doDijkstra(int[][] a) &#123; int len = a.length; // 标记已经访问过的点 int[] sign = new int[len]; // 存放当前0到个点的最短距离 int[] shortest = new int[len]; // 存放当前节点的前驱 int[] precursor = new int[len]; // 循环次数? int count = len - 1; // 初始化最短距离 System.arraycopy(a[0], 0, shortest, 0, len); // 0开始的, 所以0默认已经访问过了 sign[0] = 1; while (count &gt; 0) &#123; int min = 0x7fffffff; int pos = -1; // 从shortest中找到没标记过的点, 且距离最小的 for (int i = 0; i &lt; len; i ++) &#123; if (sign[i] == 0) &#123; if (shortest[i] &gt; 0 &amp;&amp; shortest[i] &lt; min) &#123; min = shortest[i]; pos = i; &#125; &#125; &#125; // 标记访问 sign[pos] = 1; // 修改最短路径 for (int i = 0; i &lt; len; i ++) &#123; if (a[pos][i] &gt; 0 &amp;&amp; sign[i] == 0) &#123; // -1标识无穷远, 能到达肯定比无穷远要好 if (shortest[i] == -1 || a[pos][i] + shortest[pos] &lt; shortest[i]) &#123; shortest[i] = a[pos][i] + shortest[pos]; // 修改前驱 precursor[i] = pos; &#125; &#125; &#125; count --; &#125; System.out.println("shortest: "); for (int i = 1; i &lt; len; i ++) &#123; System.out.println(0 + "-&gt;" + i); System.out.print(0 + " "); dfs(precursor, i); System.out.println(); &#125; &#125; /** * 递归输出, 为了从头输出, 好看一点 * @param a * @param end */ private static void dfs(int[] a, int end) &#123; if (end != 0) &#123; dfs(a, a[end]); System.out.print(end + " "); &#125; &#125; public static void main(String[] args) &#123; int n = s.nextInt(); int k = s.nextInt(); int[][] edges = new int[n][n]; // 输入 Dijkstra.input(n, k, edges); // 打印图 //Dijkstra.printEdges(edges); // 计算过程 doDijkstra(edges); &#125;&#125;]]></content>
      <tags>
        <tag>Dijkstra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高级同步结构]]></title>
    <url>%2F2018%2F09%2F07%2Fjuc%2F</url>
    <content type="text"><![CDATA[这些同步结构都在java.util.concurrent并发包下，这里只看一下基础的用法。 CountDownLatch直接用API来介绍吧 A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.简单说来就是让一些线程等待其他线程的操作完成 写一个示例程序: 12345678910111213141516171819202122232425262728293031323334353637383940package concurrent.countdownlatch;import java.util.concurrent.CountDownLatch;public class Test1 &#123; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(5); // 这里一般对应的操作数，这是几，就要有几次countDown操作 for (int i = 0; i &lt; 5; i ++) &#123; // 新建5个线程跑起来 MyThread myThread = new MyThread(i, countDownLatch); myThread.start(); &#125; System.out.println("prepare to wait for other thread finish work..."); countDownLatch.await(); // 要点1 System.out.println("all threads have finish work!!!"); &#125;&#125;class MyThread extends Thread &#123; private int tId; private CountDownLatch countDownLatch; public MyThread(int tId, CountDownLatch countDownLatch) &#123; this.tId = tId; this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; try &#123; // Thread.sleep(1000 * (5-tId)); // 模拟工作, 不要介意为啥这样写 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("thread i=" + tId + " has finish work"); countDownLatch.countDown(); // 要点2 &#125;&#125; 附上运行结果: 注意我注释中标记了要点的地方，CountDownLatch主要操作方式就是await/countDown，在该程序中，await在main方法中执行，从线程方面来看，就是我们的main线程在等待5个MyThread线程执行结束，就是这样 CyclicBarrier再来看看API中的第一句 A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.允许一堆线程在barrier互相等待 看个示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package concurrent.cyclicbarrier;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;public class Test2 &#123; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(5, ()-&gt;&#123; // 要点1 System.out.println("all thread arrive barrier !! "); System.out.println("let's rest a while"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); for(int j = 0; j &lt; 5; j ++) &#123; Mythread mythread = new Mythread(cyclicBarrier, j); mythread.start(); &#125; &#125;&#125;class Mythread extends Thread &#123; private CyclicBarrier cyclicBarrier; private int j; // 休息时间 public Mythread(CyclicBarrier cyclicBarrier, int j) &#123; this.cyclicBarrier = cyclicBarrier; this.j = j; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 3; i ++) &#123; try &#123; Thread.sleep(j*1000); // 模拟工作 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + " run i=" + i); try &#123; cyclicBarrier.await(); // 要点2 &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 运行结果: 先说一下要点1，在创建CyclicBarrier对象时可以传递一个Runnable对象，这个Runnable会在所有的相互等待的线程都到达barrier时执行，从运行结果可以看出来，当我们的5个线程都做完了工作执行await之后，Runnable定义的操作就会运行。 区别这里简单写一下二者的区别 CountDownLatch是一次性的, 因为初始化中传递的count在CountDownLatch中是无法被恢复的; 但是CyclicBarrier是可以用多次的，从运行结果我们也可以看出来, 这是因为CyclicBarrier内部把最初的值保留在parties中, 每次执行减法的是它的拷贝count, 当CyclicBarrier运行完一轮后, 通常会自动调用nextGeneration方法, 在该方法内部又把parties赋值给count了 逻辑上来讲, CountDownLatch是让A组线程等待B组线程全部执行完, 然后A组线程继续做该做的; CyclicBarrier是A组线程中的每个线程都做一些事到达barrier, 即进入等待状态后, CyclicBarrier可以做个总结之类的, 然后A组线程中的每一个又开始继续做事, 这样循环下去]]></content>
      <tags>
        <tag>CountDownLatch</tag>
        <tag>CyclicBarrier</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap与Hashtable的异同点]]></title>
    <url>%2F2018%2F08%2F23%2Fhashmap-hashtable%2F</url>
    <content type="text"><![CDATA[总结一下HashMap和Hashtable的区别，可能会不全，后面有发现了再补充。 并发这应该是最明显的一点不同了，HashMap不是线程安全的，但是Hashtable是的，看一下Hashtable中的方法，基本上都加了synchronized，但是呢，这种同步实在是太粗糙了，所以在并发的情况下才会推荐使用ConcurrentHashMap吧。 构造方式默认容量在构建相应的实例时，如果没有指定initialCapacity，HashMap默认指定为16，Hashtable默认指定为11： 123456789101112//Hashtable默认构造函数public Hashtable() &#123; this(11, 0.75f);&#125;/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125; 创建桶他们两个实际创建桶的时机也是不一样的，HashMap应该是懒加载： 1234567891011121314151617181920212223242526272829303132333435363738public Hashtable(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal Load: "+loadFactor); if (initialCapacity==0) initialCapacity = 1; this.loadFactor = loadFactor; table = new Entry&lt;?,?&gt;[initialCapacity]; // 在这里就为桶分配内存了 threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1);&#125;//但是在HashMap的构造函数中，找不到类似的为桶分配内存的命令，//因为在分配内存是在resize()方法中，这里截取部分Node&lt;K,V&gt;[] oldTab = table;int oldCap = (oldTab == null) ? 0 : oldTab.length; // 由于没有分配内存，所以此时table还是null，因此oldCap == 0int oldThr = threshold;int newCap, newThr = 0;if (oldCap &gt; 0) &#123; // ...&#125;else if (oldThr &gt; 0) // 注意如果新建HashMap时指定了initialCapacity，那么会根据这个值初始化 threshold newCap = oldThr;else &#123; // 这里就是啥都没指定的 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);&#125;if (newThr == 0) &#123; // 确定新阀值 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);&#125;threshold = newThr;@SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 呐呐，在这分配内存table = newTab; // 我们的table不为null了 hashHashtable计算元素的hash值是这样的： 12int hash = key.hashCode();int index = (hash &amp; 0x7FFFFFFF) % tab.length; 而HashMap就比较精致了： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 一个是求余，一个是位运算，效率肯定也不一样。 结构虽然从整体上来看，HashMap和Hashtable都是用链地址法解决冲突，但是1.8的HashMap作了优化，当冲突超过一定时，会将链表进行树化。 扩容两个数据结构扩容的方式也不同，Hashtable就比较简单了，扩大容量后，把旧table中的点遍历一遍，重新计算hash值采用头插法放到新table中；而HashMap就不一样了，除了要考虑树的情况，在从旧table放到新table的过程中，是先把旧table中的冲突链表或树，分成两份，放进新table中(具体的可以看这：https://zero22.top/2018/08/17/HashMap-%E4%B8%80/)。 总结对比一下HashMap和Hashtable，不得不佩服Josh Bloch、Arthur van Hoff、Neal Gafter、Doug Lea等作者，总是在不断的优化、创新，让我看到这么漂亮的code，感谢。 - -]]></content>
      <tags>
        <tag>HashMap</tag>
        <tag>Hashtable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hashtable]]></title>
    <url>%2F2018%2F08%2F22%2FHashtable%2F</url>
    <content type="text"><![CDATA[基本上不会用到了，在官方API中这样写道： Unlike the new collection implementations, Hashtable is synchronized. If a thread-safe implementation is not needed, it is recommended to use HashMap in place of Hashtable. If a thread-safe highly-concurrent implementation is desired, then it is recommended to use ConcurrentHashMap in place of Hashtable. 如果必须需要线程安全，请用HashMap；如果高并发线程安全是必要的，请用ConcurrentHashMap。不过还是来了解一下吧，看看Hashtable为啥被抛弃了。 put1234567891011121314151617181920212223public synchronized V put(K key, V value) &#123; // Make sure the value is not null if (value == null) &#123; throw new NullPointerException(); &#125; // Makes sure the key is not already in the hashtable. Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings("unchecked") Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index]; for(; entry != null ; entry = entry.next) &#123; if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123; V old = entry.value; entry.value = value; return old; &#125; &#125; addEntry(hash, key, value, index); return null;&#125; 从put中我们可以知道下面几点： value不能为null，其实key也不能为null； 索引的计算方法 (hash &amp; 0x7FFFFFFF) % tab.length ，这个叫做除留余数法，用到了取模，可能会影响效率。 当产生冲突时，用链地址法解决冲突，并且采用头插法把新来的插在首位。 当经过上面的步骤还没有处理新来的key-value，就交给addEntry 12345678910111213141516171819private void addEntry(int hash, K key, V value, int index) &#123; modCount++; Entry&lt;?,?&gt; tab[] = table; if (count &gt;= threshold) &#123; // Rehash the table if the threshold is exceeded rehash(); tab = table; hash = key.hashCode(); index = (hash &amp; 0x7FFFFFFF) % tab.length; &#125; // Creates the new entry. @SuppressWarnings("unchecked") Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index]; tab[index] = new Entry&lt;&gt;(hash, key, value, e); count++;&#125; 这个modCount后面再说 首先判断hashtable中的键值对的数量是否超过了阀值，超过了要先扩容再重新计算index，否则直接插入。要注意的是这种情况，在put的过程中，hash冲突了，但是key值不一样，这时候也还是要到addEntry中，但是我们看好像并没有把这个新的key-value插入到链表呀，但其实看看这个new Entry&lt;&gt;(hash, key, value, e) 就会发现key-value是在这个时候被放到e的前边了，还是头插法。 再来继续看rehash 1234567891011121314151617181920212223242526272829protected void rehash() &#123; int oldCapacity = table.length; Entry&lt;?,?&gt;[] oldMap = table; // overflow-conscious code int newCapacity = (oldCapacity &lt;&lt; 1) + 1; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) &#123; if (oldCapacity == MAX_ARRAY_SIZE) // Keep running with MAX_ARRAY_SIZE buckets return; newCapacity = MAX_ARRAY_SIZE; &#125; Entry&lt;?,?&gt;[] newMap = new Entry&lt;?,?&gt;[newCapacity]; modCount++; threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1); table = newMap; for (int i = oldCapacity ; i-- &gt; 0 ;) &#123; for (Entry&lt;K,V&gt; old = (Entry&lt;K,V&gt;)oldMap[i] ; old != null ; ) &#123; Entry&lt;K,V&gt; e = old; old = old.next; int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity; e.next = (Entry&lt;K,V&gt;)newMap[index]; newMap[index] = e; &#125; &#125;&#125; 逻辑比较简单： 1.容量扩大一倍加一，最多能有0x7fffffff-8个桶 2.按照新容量重建一个hashtable 3.计算阀值 4.把旧table中的点按照新table的长度重新计算索引，放到新table中，采用头插法 get很简单，就看看 1234567891011public synchronized V get(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return (V)e.value; &#125; &#125; return null;&#125; contains123456789101112131415161718192021222324252627282930313233//这个其实就是判断是否包含某个value，看下边的containsValue就知道//判断包含value比判断包含key的代价更高，因为直接判断包含value需要遍历整个hashtablepublic synchronized boolean contains(Object value) &#123; if (value == null) &#123; throw new NullPointerException(); &#125; Entry&lt;?,?&gt; tab[] = table; for (int i = tab.length ; i-- &gt; 0 ;) &#123; for (Entry&lt;?,?&gt; e = tab[i] ; e != null ; e = e.next) &#123; if (e.value.equals(value)) &#123; return true; &#125; &#125; &#125; return false;&#125;public boolean containsValue(Object value) &#123; return contains(value);&#125;public synchronized boolean containsKey(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return true; &#125; &#125; return false;&#125; forEach1234567891011121314151617public synchronized void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; Objects.requireNonNull(action); // explicit check required in case // table is empty. final int expectedModCount = modCount; Entry&lt;?, ?&gt;[] tab = table; for (Entry&lt;?, ?&gt; entry : tab) &#123; while (entry != null) &#123; action.accept((K)entry.key, (V)entry.value); entry = entry.next; if (expectedModCount != modCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125;&#125; 这个方法是jdk1.8新增的，支持lambda表达式，下次要遍历时可以.一下看看有没有forEach， 有的话就可以这样遍历了： 123456789101112131415161718Hashtable&lt;Integer, String&gt; hashtable = new Hashtable&lt;&gt;();hashtable.put(1, "one");hashtable.put(0, "two");hashtable.put(5, "five");hashtable.put(2, "two");hashtable.put(100, "hundred");hashtable.put(55, "fifty five");hashtable.forEach((key, value) -&gt; System.out.println("key: " + key + " value: " + value));//output----------------------------------------------key: 55 value: fifty fivekey: 0 value: twokey: 100 value: hundredkey: 1 value: onekey: 2 value: twokey: 5 value: five otherfail-fast上面看到了一个变量，叫做modCount，我理解为修改次数，在绝大多数集合或Map中都能看到这个值(至于是不是绝大多数我也不太确定，后面看的多了在作修改)，看一下官方对这个值的解释： The number of times this Hashtable has been structurally modifiedStructural modifications are those that change the number of entries inthe Hashtable or otherwise modify its internal structure (e.g.,rehash). This field is used to make iterators on Collection-views ofthe Hashtable fail-fast. (See ConcurrentModificationException). 大概就是当Hashtable发生结构变化(比如增删entry、rehash等)时，这个值就会自加一表示Hashtable被修改了。这个值主要用于iterator的fail-fast机制，对于该机制Hashtable也作了解释： if the Hashtable is structurally modified at any timeafter the iterator is created, in any way except through the iterator’s ownremove method, the iterator will throw a ConcurrentModificationException. 当迭代器创建后，任何非迭代器产生的结构变化都会抛出ConcurrentModificationException异常，再找找具体的使用吧： 123456789101112131415161718public synchronized void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Objects.requireNonNull(function); // explicit check required in case // table is empty. final int expectedModCount = modCount; Entry&lt;K, V&gt;[] tab = (Entry&lt;K, V&gt;[])table; for (Entry&lt;K, V&gt; entry : tab) &#123; while (entry != null) &#123; entry.value = Objects.requireNonNull( function.apply(entry.key, entry.value)); entry = entry.next; if (expectedModCount != modCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125;&#125; 其实上边的forEach也有用到，来分析一下： 首先在任何操作之前，记录此时的modCount值 遍历hashtable进行替换操作 每当替换一个entry.value后，都要比较现在的modCount和刚在记录的expectedModCount是否一致，如果不一致就会抛出异常。 看起来似乎可以保证并发安全? 不！再来看看官方说明： Note that the fail-fast behavior of an iterator cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification.the fail-fast behavior of iterators should be used only to detect bugs. fail-fast机制只用来检测程序bug！ fail-safe参考这里除了fail-fast，还有另一种机制fail-safe，简单说来就是： 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。]]></content>
      <tags>
        <tag>fail-fast</tag>
        <tag>Hashtable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次WEB请求全过程]]></title>
    <url>%2F2018%2F08%2F21%2Fweb-request%2F</url>
    <content type="text"><![CDATA[输入URL首先，用户在Web浏览器（如IE）地址栏输入URL，比如：https://zero22.top 前面的https是协议类型，后面的zero22.top指定被访问的服务器的域名，没有加冒号和端口号表示访问的是默认的端口号80。 DNS解析由于所发出的数据要通过被访问主机的IP地址进行传输和路由，所以要先通过DNS服务器将域名解析为IP地址： 主机产生一个DNS请求，传递给传输层，通过UDP产生一个UDP报文；再传递给网络层产生一个IP报文，目的地址是DNS服务器的IP地址；在数据链路层通过ARP协议得到到达DNS服务器的下一跳的MAC地址；把数据帧通过以太网传输给DNS服务器。 DNS服务器将收到的帧向上传给传输层，得到UDP报文。通过UDP报文中指定的端口号传给DNS应用程序。这里，由于是内网域名和内网DNS服务器，DNS服务器中有相应的表项，如果不在当地，本地DNS服务器还要向上级的DNS服务器发出DNS查询请求，如此递归直到查到要解析的域名的IP地址。 DNS把通过DNS应答将得到的IP地址返回给请求的主机。 HTTP嘶挞哆现在，浏览器得到对方的IP地址了，即进入HTTP流程。HTTP的工作流程分为以下四步： 通过三次握手建立TCP连接。 客户端发送请求给服务器。 服务器收到请求后，给予相应的响应消息，并传输相应的响应数据给客户端。 客户端接收完服务器返回的信息后，与服务器断开连接。 THREE-WAY HANDSHAKE用Wireshark来看看三次握手： 首先我给服务器发送一个TCP报文：随后服务器端回我一个：最后我再给服务器发一个：由上边可以知道，客户端和服务器端发送的Sequence number是没有关系的，各自算各自的。 至于建立连接之后，客户端与服务器端数据的传送，现在不想看了，大概根据对方的ip和mac地址，传到相应的主机？解析后主机在给相应的应用程序？不很清楚，再看吧 - -]]></content>
      <tags>
        <tag>web请求</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NavigableMap/NavigableSet]]></title>
    <url>%2F2018%2F08%2F21%2FNavigableSet-NavigableMap%E5%8F%8ASortedSet-SortedMap%2F</url>
    <content type="text"><![CDATA[navigation英 [ˌnævɪˈgeɪʃn] 美[ˌnævɪˈɡeʃən]noun[U]导航；领航the skill or the process of planning a route for a ship or other vehicle and taking it there 前边大概看了 TreeMap和TreeSet，更多的细节今后有需求在研究吧，再来看看他们分别实现的接口NavigableSet/NavigableMap，他们分别继承了SortedSet/SortedMap。 NavigableMap其中主要的方法都和其名称相符，即导航，查找和指定目标最接近的值，或是大于，或是小于；主要分为两类，找key或者找Entry： 123//返回key值大于或等于指定key的Entry或KeyMap.Entry&lt;K,V&gt; ceilingEntry(K key);K ceilingKey(K key); 123//小于等于的Map.Entry&lt;K,V&gt; floorEntry(K key);K floorKey(K key); 12345//不包括等于Map.Entry&lt;K,V&gt; lowerEntry(K key);K lowerKey(K key);Map.Entry&lt;K,V&gt; higherEntry(K key);K higherKey(K key); 12NavigableSet&lt;K&gt; descendingKeySet();NavigableMap&lt;K,V&gt; descendingMap(); 返回按照key值降序的集合；返回的集合和原集合是相互联系的(The descending map is backed by this map)，修改任一集合都会对另外一个集合产生影响；用迭代器遍历集合的同时修改集合，那么遍历的结果是不确定的。下面写几个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void testDesc() &#123; NavigableMap&lt;Integer, String&gt; map = new TreeMap&lt;&gt;(); map.put(1,"one"); map.put(-1, "negative one"); map.put(56, "fifty six"); map.put(9, "nine"); map.put(0, "zero"); map.put(20, "twenty"); System.out.println("before desc---------------------"); for (Map.Entry&lt;Integer,String&gt; ele: map.entrySet() ) &#123; System.out.println(ele.getKey() + " " + ele.getValue()); &#125; NavigableMap&lt;Integer, String&gt; descMap = map.descendingMap(); System.out.println("after desc-----------------------"); for (Map.Entry&lt;Integer,String&gt; ele: descMap.entrySet() ) &#123; System.out.println(ele.getKey() + " " + ele.getValue()); &#125; descMap.put(100, "one hundred"); System.out.println("after desc put-------------------"); for (Map.Entry&lt;Integer,String&gt; ele: map.entrySet() ) &#123; System.out.println(ele.getKey() + " " + ele.getValue()); &#125;&#125;result：before desc----------------------1 negative one0 zero1 one9 nine20 twenty56 fifty sixafter desc-----------------------56 fifty six20 twenty9 nine1 one0 zero-1 negative oneafter desc put--------------------1 negative one0 zero1 one9 nine20 twenty56 fifty six100 one hundred 当我在逆序集合中插入新Entry后，在遍历原来的map也打印了新加入的Entry，所以是相互影响的。 1234//返回key值小于toKey的Entry组成的Map，也是相互关联的，需要注意的是，在headMap中新增Entry时，新Entry的key值同样不能大于toKey，否则会抛出异常；inclusive用来表示是否包括toKeyNavigableMap&lt;K,V&gt; headMap(K toKey, boolean inclusive);//对应于headMap，返回大于fromKey的NavigableMap&lt;K,V&gt; tailMap(K fromKey, boolean inclusive); 突然感觉没有写的必要？ NavigableSetset中的操作基本上就是map中对于key的操作，下面放一些方法： 1234567E lower(E e);E floor(E e);E ceiling(E e);E higher(E e);NavigableSet&lt;E&gt; descendingSet();NavigableSet&lt;E&gt; headSet(E toElement, boolean inclusive);NavigableSet&lt;E&gt; tailSet(E fromElement, boolean inclusive); 唯一有点区别的就是Set中多了迭代器iterator，毕竟Collection继承了Iterator 12Iterator&lt;E&gt; iterator();Iterator&lt;E&gt; descendingIterator(); 至于他们的父类Sorted一族也是接口，没什么好看的。在jdk1.8中，为集合新增了Spliterator(并行迭代器?)这个玩意，后边再看吧 - -]]></content>
      <tags>
        <tag>NavigableMap</tag>
        <tag>NavigableSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TreeMap与TreeSet]]></title>
    <url>%2F2018%2F08%2F20%2FTreeMap%2F</url>
    <content type="text"><![CDATA[我们知道，map中的元素是由键值对组成的，TreeMap就是把这些键值对通过某个因素连接组成树的一种数据结构。其中TreeMap中的树是红黑树，在构造TreeMap对象时，可以选择传入一个比较器Comparator，如果没传的话，那么TreeMap中元素的key需要实现Comparable接口，这个规定是强制的，不然会有异常。下面看看常用的方法，说是常用我却没用过，还有一个TreeSet，放一起看看。jdk1.8版本的。 TreeMapput12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = root; if (t == null) &#123; compare(key, key); // type (and possibly null) check root = new Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; else &#123; if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; fixAfterInsertion(e); size++; modCount++; return null;&#125; 不是很难，如果树为空，就新建root；否则根据Comparator/Comparable比较key值，如果key值已经存在了，直接用新value覆盖之；不然就找到插入点进行插入，最后作调整。TreeMap的作者也参与了HashMap的编写，但是其中红黑树调整的写法却不一样。 getEntry这里就写个最简单的get方法吧，里边还有各种get方法，比如模糊查找，找比特定值大的部分中的最小的，或者比特定值小的部分中最大的等等， 1234567891011121314151617181920final Entry&lt;K,V&gt; getEntry(Object key) &#123; // Offload comparator-based version for sake of performance if (comparator != null) return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; return null;&#125; 按照Comparator或者Comparable来查找指定的key。 successor个人认为这个方法也挺重要的，不过一般我们不用，他为TreeMap中其他方法提供，用来返回特定Entry的后继节点，即比他大的且最靠近他的 123456789101112131415161718static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) &#123; if (t == null) return null; else if (t.right != null) &#123; Entry&lt;K,V&gt; p = t.right; while (p.left != null) p = p.left; return p; &#125; else &#123; Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; while (p != null &amp;&amp; ch == p.right) &#123; ch = p; p = p.parent; &#125; return p; &#125;&#125; 比指定Entry大的值出现在两个地方，Entry的右孩子或者Entry所在的子树为另一子树的左孩子。 TreeSet什么都不说，让我们看看TreeSet的构造函数吧： 123456789101112131415public TreeSet() &#123; this(new TreeMap&lt;E,Object&gt;());&#125;public TreeSet(Comparator&lt;? super E&gt; comparator) &#123; this(new TreeMap&lt;&gt;(comparator));&#125;TreeSet(NavigableMap&lt;E,Object&gt; m) &#123; this.m = m;&#125;//以及一些成员变量private transient NavigableMap&lt;E,Object&gt; m;private static final Object PRESENT = new Object(); 原来TreeSet就是把TreeMap包装一下? 你是对的 再来看看他的一些方法 123public boolean add(E e) &#123; return m.put(e, PRESENT)==null;&#125; // 哈哈，Entry不够，Object来凑 其他的方法就是 NavigableSet接口中的方法了，主要是给定搜索目标报告最接近匹配项的导航方法，比如： 123public E ceiling(E e) &#123; return m.ceilingKey(e);&#125; 等都是调用TreeMap中关于key的操作。 over]]></content>
      <tags>
        <tag>TreeMap</tag>
        <tag>TreeSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap(二)]]></title>
    <url>%2F2018%2F08%2F20%2Fhashmap2%2F</url>
    <content type="text"><![CDATA[jdk1.8中的HashMap额外引用了红黑树，当冲突链表太长的话，就会把链表转化为红黑树的结构，避免了原来的当冲突太多了，查找效率可能会退化到O(n)的情况。红黑树在HashMap中表现为TreeNode，下面看一下主要的方法。 treeify具体的树化过程，但是里边有个地方我不是太明白： 1234567891011121314151617181920212223for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; root = balanceInsertion(root, x); break; &#125;&#125; 上边是查找插入点的过程，这个h是链表中待插入的点的hash值，ph是树中的点的hash值，话说为什么要先比较这俩呢，既然在一条冲突链表里，hash值还能不一样吗?所以一般情况下，插入树中主要比较的是他们的key值，如果key值也一样就比较两个节点的原始hashcode，原始hashcode也相等被包含在-1中。 untreeify解除树化，树中节点数小于等于6，就会转化为链表。主要操作就是把链表中的TreeNode变成Node。链表中的点称为 Node，红黑树中的点称为 TreeNode，这个TreeNode最终还是继承的该Node，链表主要用pre、next等，树主要用left、right、parent等，所以这两种点可以相互转化。 split只在resize时使用，首先根据next、pre把树分成lo和hi两条链表，放到新table中，如果长度大于6再树化。 红黑树红黑树的规则： 根节点是黑的 叶子是黑的 树中的节点是黑或红 红色节点的孩子是黑的 从任一节点开始到能到的叶子，经过的黑色节点数目是一样的 具体看wiki 其他关于HashMap其他的我认为没什么好看的了，最后把get也一起放这就结束吧。 1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 在经过了put之后，我感觉get就没啥好说的，找到索引位置，从第一个开始往后找，如果是树的话就用红黑树的找法。 over.]]></content>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap(一)]]></title>
    <url>%2F2018%2F08%2F17%2Fhashmap1%2F</url>
    <content type="text"><![CDATA[打算看看关于Collection/Map的源码，先拿HashMap试试手吧，这一篇主要看看HashMap的put方法，把与其相关的方法都揪出来。注意，源码是jdk1.8版本的 put123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 这里有个计算key的hash值得方法， hash1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 这个方法简单说来就是，为了尽量减少冲突，并且还要考虑效率，在计算key的hash值时，也让hashCode的高位参与运算。 putVal123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 哇，怎么这么长，别着急，我们慢慢看，后边还有更长的呢。 首先，如果当前的”篮子”为空或者长度为0，那么很明显需要初始化，用到了resize() ； 接下来，我们可以看到索引值得计算方法： (n-1) &amp; hash其中n为table的长度，都是2次幂，那么n-1 就是这样的了： 11…111hash为前面计算的高位和低位都参与的hash值从这里可以看出来，table的索引值是依靠hash值得低几位决定的。如果当前索引没被占过，那么新Node直接放这就完事了。 下边就是更新值的操作了如果老点的hash值和key值和新点相同，记录老点；如果老点所在的”篮子”后边跟的太多了，导致变异成了树，把新点放到树里边putTreeVal(this, tab, hash, key, value) ，记录返回值；最后来个循环，在”篮子”后边的链表中继续找，没找到就把新点加在链表的最后，注意，加完了要判断链表的长度是否大于树化的临界值8，可能要进行树化 treeifyBin(tab, hash) ；上面三种可能都记录了老点，但是putTreeVal()目前不知道返回什么，先不管了，老点都被e记录了，如果e不为空，说明新点和老点重复了，要进行覆盖，最后返回老点的值， 如果没有更新值，说明新点被添加到table中了，接下来要判断table的大小有没有超过阀值，如果超过阀值又要resize()，最后返回null。 下面再来看看putVal中涉及到的各种方法： resize初始化table或者table容器超过阀值都要进行resize 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 先把table的长度、阀值什么的确定下来 如果老table存在，即其长度大于0，如果长度大于2^30，那就不用重建了，因为长度已经是最大值了，把阀值调到Integer.MAX_VALUE；否则，老table长度扩大一倍，阀值也扩大一倍； 老table长度为0，新table长度为阀值； 如果老table长度为0，并且老阀值不大于0，那就按默认的来，长度16，阀值12 下边就是把老table中的点放到新table中的过程了 循环遍历每个老点 如果该点没有冲突，直接放新table中； 如果该点后面跟着树，那么((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap) 否则该点后边就是不算长的冲突链表了； 创建两个链表，用来减少冲突，遍历链表时，划分某一点的依据是 (e.hash &amp; oldCap) == 0，由于table的长度都是2的次幂，比如长度为16时，oldCap为00010000，产生冲突的点中，其hash值的低四位是一样的，比如这两个：e1.hash=11010101，e2.hash=10100101，他们最后四位是一样的，但是oldCap位就说不准了，比如e1是1，e2是0，这样他们就被放到不同的链表 loHead、hiHead中了。所以老table中的一条冲突链表到新table中变成两条冲突链表了； 最后是两个新冲突链表在新表中的位置，一个不变，一个在原位的基础上位移老table长度的距离。 关于和树相关的操作，等我把红黑树那个了再说吧- -]]></content>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的Enum]]></title>
    <url>%2F2018%2F08%2F16%2Fenum-in-java%2F</url>
    <content type="text"><![CDATA[最近看java内存模型讲 volatile时候，举了一个DCL(Double Check Lock?)双重检测的单例模式，让我想到了之前看过的枚举实现单例模式，感觉很神奇而且陌生，讲道理，我基本上没怎么用过枚举，还是我见识太少了吧，所以我打算看看这个Enum是怎么回事。 初识一般用枚举的话，我们一般用的是 “enum”，而不是”Enum”，就好比 “class” 和 “Class”一样。枚举是一种特殊的类，声明时用”enum”，就像接口用”interface”一样，写个简单的例子: 123456789101112public enum EnumTest&#123; ENUM1; EnumTest()&#123; System.out.println("this is EnumTest()"); &#125; private void nothing() &#123; System.out.println("nothing"); &#125; public static void main(String[] args)&#123; EnumTest.ENUM1.nothing(); &#125;&#125; 看起来和一个类没什么区别，可以有 成员变量、方法什么的，但是这也只是看起来而已。 深入下面我们更加深入的看一看这个enum到底是什么玩意，直接反编译： 1234567891011121314151617181920212223242526272829303132333435363738394041public final class EnumTest extends java.lang.Enum&lt;EnumTest&gt; &#123; public static final EnumTest ENUM1; public static EnumTest[] values(); Code: 0: getstatic #1 // Field $VALUES:[LEnumTest; 3: invokevirtual #2 // Method "[LEnumTest;".clone:()Ljava/lang/Object; 6: checkcast #3 // class "[LEnumTest;" 9: areturn public static EnumTest valueOf(java.lang.String); Code: 0: ldc #4 // class EnumTest 2: aload_0 3: invokestatic #5 // Method java/lang/Enum.valueOf:(Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/Enum; 6: checkcast #4 // class EnumTest 9: areturn public static void main(java.lang.String[]); Code: 0: getstatic #11 // Field ENUM1:LEnumTest; 3: invokespecial #12 // Method nothing:()V 6: return static &#123;&#125;; Code: 0: new #4 // class EnumTest 3: dup 4: ldc #13 // String ENUM1 6: iconst_0 7: invokespecial #14 // Method "&lt;init&gt;":(Ljava/lang/String;I)V 10: putstatic #11 // Field ENUM1:LEnumTest; 13: iconst_1 14: anewarray #4 // class EnumTest 17: dup 18: iconst_0 19: getstatic #11 // Field ENUM1:LEnumTest; 22: aastore 23: putstatic #1 // Field $VALUES:[LEnumTest; 26: return&#125; 哇，可以看到我之前在枚举类中加入的 “ENUM1”竟然是这个类的静态实例，而且还是final的，那么这里有个问题，final变量在使用之前必须初始化，但是我们看到这里只是声明，并没有初始化。我们继续往下看，发现还有一个静态代码块！这一下应该能猜到ENUM1是在静态代码块里初始化的，我们来看看。 new 在java堆上为EnumTest对象分配内存空间，并将地址压入操作数栈顶 dup 复制操作数栈顶值，并将其压入栈顶，也就是说此时操作数栈上有连续相同的两个对象地址 ldc 把常量池中 ENUM1 推送至栈顶 invokespecial 指令调用实例初始化方法”\“:(Ljava/lang/String;I)V 看到这大概也就清楚了，静态代码块中确实会初始化ENUM1，这也解决了我的一个疑惑，看下面的程序： 12345678910public enum EnumOut&#123; ONE,TWO; EnumOut()&#123; System.out.println("this is constructor"); &#125; public static void main(String[] args)&#123; System.out.println("this is main"); &#125;&#125; 直接给出输出： 123this is constructorthis is constructorthis is main 在没有分析字节码之前，我不懂为什么会执行构造函数，但现在，豁然开朗。另外，要注意enum的构造方法只能是private的。 实现单例模式下面看看如何使用枚举实现单例模式： 12345678910111213141516171819202122public enum SingletonEnum&#123; INSTANCE; private Singleton instance; private SingletonEnum() &#123; instance = new Singleton(); &#125; public Singleton getInstance()&#123; return instance; &#125; public static void main(String[] args)&#123; Singleton single1 = SingletonEnum.INSTANCE.getInstance(); Singleton single2 = SingletonEnum.INSTANCE.getInstance(); System.out.println(single1 == single2); &#125;&#125;class Singleton&#123; private int id;&#125; 在jvm第一次加载SingletonEnum类时，INSTANCE就已经被定死了，后边调用SingletonEnum.INSTANCE.getInstance() 方法时得到的都是INSTANCE对象中的Singleton，所以保证了单例。]]></content>
      <tags>
        <tag>enum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 5. Longest Palindromic Substring]]></title>
    <url>%2F2018%2F08%2F14%2Fmanacher%2F</url>
    <content type="text"><![CDATA[给你一个字符串，找到一个最长的回文子串，例如，”banana”字符串的最长回文子串为”anana”，这里说的找到一个是因为一个字符串可能有多个长度相同的回文子串，这里只用返回一个就可以了。另外要区分一下回文子串和回文子序列，其实就是子串和子序列的区别。参考文章：Longest Palindromic Substring Part II维基百科：Longest palindromic substring 简化字符串首先，为了避免奇数和偶数长度的影响，我们在字符串中增加特殊符号’#’，这里我自己想这一题的时候也用了这个方法，这样加完特殊符号后，新的字符串总是奇数长度，然后在求回文串的时候，每个字符都可以当做中间值，比较他两边的字符是否相同即可。“ababa” –&gt; “#a#b#a#b#a#” 找规律在我的感觉中，算法应该就是把事物中的规律用语句表示出来，所以下面我们来看看计算最长回文子串中的规律。用一个额外的数组记录每个点为中心时的对称长度。其中C表示当前回文串的中心，L、R分别表示当前回文串的左端和右端，i为待求，i’为i关于C的对称索引，现在让你求以i为中心的回文串的最大长度，你会怎么求。我们看到，以C为中心，他两边不超过L/R的字符串都是对称的，所以我们可以直接确定P[i] = p[i’]，这样就省了一部分求P的时间。我自己做的没有用到以求的数据，每个地方都是比较他两边的字符，这样显然很浪费时间，但是Manacher算法在计算回文串长度时，用到了前边的数据，这里我第一时间想到了KMP算法求子串的长度。然后我们继续：当i=15时，能直接说P[15] = P[7] 吗，你要知道，我们前边能直接根据镜像求P有个条件，那就是我们的镜像的边界都没超过L/R，也就是能确保C两边的字符串是一模一样的，但是这里，P[7] = 7，超过了边界L，再看一张图绿色实线表示左右两边一定相同的并且P[i]一定会包含的，绿色虚线表示相同但是不一定包含在P[i]中，这里要取决于红色实线的部分，也就是说镜像得来的便利也就到R为止了，后边的就要靠自己去比较两边的字符了。总结规律： 123if P[i'] &lt; R-ithen P[i] = P[i']else P[i] &gt;= R-i 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// Transform S into T.// For example, S = "abba", T = "^#a#b#b#a#$".// ^ and $ signs are sentinels appended to each end to avoid bounds checkingstring preProcess(string s) &#123; int n = s.length(); if (n == 0) return "^$"; string ret = "^"; for (int i = 0; i &lt; n; i++) ret += "#" + s.substr(i, 1); ret += "#$"; return ret;&#125;string longestPalindrome(string s) &#123; string T = preProcess(s); int n = T.length(); int *P = new int[n]; int C = 0, R = 0; for (int i = 1; i &lt; n-1; i++) &#123; int i_mirror = 2*C-i; // equals to i' = C - (i-C) P[i] = (R &gt; i) ? min(R-i, P[i_mirror]) : 0; // Attempt to expand palindrome centered at i while (T[i + 1 + P[i]] == T[i - 1 - P[i]]) P[i]++; // If palindrome centered at i expand past R, // adjust center based on expanded palindrome. if (i + P[i] &gt; R) &#123; C = i; R = i + P[i]; &#125; &#125; // Find the maximum element in P. int maxLen = 0; int centerIndex = 0; for (int i = 1; i &lt; n-1; i++) &#123; if (P[i] &gt; maxLen) &#123; maxLen = P[i]; centerIndex = i; &#125; &#125; delete[] P; return s.substr((centerIndex - 1 - maxLen)/2, maxLen);&#125;]]></content>
      <tags>
        <tag>Manacher</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[原子类AtomicInteger的自增]]></title>
    <url>%2F2018%2F08%2F13%2FatomicInteger%2F</url>
    <content type="text"><![CDATA[包 java.util.concurrent.atomic 下有很多原子类，可以在不使用锁的前提下实现并发，下面就AtomicInteger来深入看看原子类。 成员变量1234567891011121314private static final long serialVersionUID = 6214790243416807050L;// setup to use Unsafe.compareAndSwapInt for updatesprivate static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value; Unsafe类提供了像C/C++那样操作内存的方法，在很多地方都有用到Unsafe类。由于Unsafe类中大多都是native方法，没有提供源码，连注释都没有(jdk1.8)，看起来有点不爽。 Unsafe.objectFieldOffset()方法返回成员变量相对于对象位置的偏移量(而且这个偏移量也有点意思)，举个例子，假设Book类有个成员变量bookName，且偏移量为12，那么当新建一个Book对象，对象地址为 0x1a3234c3(这地址我瞎举的)，那么bookName的地址就是(0x1a3234c3 + 12)。该方法需要一个java.lang.reflect.Field参数，和反射有关。 value变量保存了当前的对象的值，这个变量被volatile修饰了，即当有多个线程时，只要该变量修改了，能保证其他线程在用这个值得时候是最最最新的。后边也打算写一下volatile。 重点方法12345678/** * Atomically increments by one the current value. * * @return the updated value */public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 这个方法实现了AtomicInteger的自增1操作，而且是原子的。我们知道，在多线程的环境下使用 num++，最终的结果可能会和预期有差异，这是由于num++不是原子性的，需要读取、加、写入，在这些过程中，可能会丢失掉一部分的写入操作，和数据库中的第二类丢失更新类似。那么这个方法为什么是原子性的呢? 把相关的方法都找出来: 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 很不幸的是，getAndAddInt()里边的两个方法都是native，在java中没有源码。这里我们来实际用用这些方法。 实例化UnsafeUnsafe使用了单例模式: 123456789@CallerSensitivepublic static Unsafe getUnsafe() &#123; Class var0 = Reflection.getCallerClass(); if (!VM.isSystemDomainLoader(var0.getClassLoader())) &#123; throw new SecurityException("Unsafe"); &#125; else &#123; return theUnsafe; &#125;&#125; 虽然是单例模式，但不是你想getUnsafe就能得到Unsafe的，他被设计成只有引导类加载器(bootstrap class loader)加载才能返回 Unsafe实例。 这里看文章都写了两种方法，一种是加jvm参数，另一种是反射。加jvm参数我没成功，所以说说反射吧。 123Field field = Unsafe.class.getDeclaredField("theUnsafe");field.setAccessible(true);Unsafe unsafe = (Unsafe) field.get(null); 这里有点反射的知识，当Field为成员变量时，field.get(not null)必须有个对象参数，否则会有空指针异常；如果Field是静态变量，那么就不需要对象作为参数了。 方法调用先来试试getIntVolatile方法。 1public native int getIntVolatile(Object var1, long var2); 两个参数，var1为对象，var2为变量偏移量 123456789101112class UserTwo &#123; private String name = "default"; private int userName = 12; private int fieldTwo = 2; private static String staticString = "static string";&#125;Field field1 = UserTwo.class.getDeclaredField("userName");field1.setAccessible(true);// 域偏移量long offset = unsafe.objectFieldOffset(field1);System.out.println("getInt: " + unsafe.getInt(userTwo, offset)); 上边用的getInt，和getIntVolatile大同小异，应该根据具体变量进行选择，输出结果: 1getInt: 12 所以这个方法作用为，根据变量的相对偏移量，得到具体对象的属性值 再来看看compareAndSwapInt方法 1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 根据上面的分析，var1，var2用来获取对象属性值，var4为期望值，var5为目标值，写一些示例: 123456System.out.println("getAndAddInt: " + unsafe.getAndAddInt(userTwo, offset, 12));System.out.println("test=" + field1.get(userTwo));System.out.println("compareAndSwapInt: " + unsafe.compareAndSwapInt(userTwo, offset , 24, 23));System.out.println("test=" + field1.get(userTwo));System.out.println("compareAndSwapInt: " + unsafe.compareAndSwapInt(userTwo, offset , 45, 24));System.out.println("test=" + field1.get(userTwo)); 输出结果: 123456getAndAddInt: 12test=24compareAndSwapInt: truetest=23compareAndSwapInt: falsetest=23 getAndAddInt，当执行成功时，即实际属性值和期望值相同，即那段时间内内存中的值没有修改过，可以更新，则返回旧值，但其实这时实际内存中的值已经更新了，12+12，所以得到24；而 compareAndSwapInt，当执行成功时返回true，并将内存中的值更新为目标值，否则返回false。 所以，getAndAddInt方法的大致流程为，取内存中的值，把该值当做目标值，在compareAndSwapInt中在此比较内存中的值和目标值是否相同，如果相同说明其他线程没有修改该变量，此线程可以进行修改，但是具体的修改过程我就不知道，可能还需要看下C++代码吧]]></content>
      <tags>
        <tag>unsafe</tag>
        <tag>automic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Comparator/Comparable]]></title>
    <url>%2F2018%2F08%2F10%2FComparator-Comparable%2F</url>
    <content type="text"><![CDATA[关于java中的Comparator和Comparable，经常会看到，但是因为没有深入的研究，老是把这两个东西搞混淆，很烦，在这里总结一下。 字面意思Comparator: 比较器，就像是一个工具一样。Comparable: 可比较的，描述一个类本身的属性。 java.util.Comparator最主要的方法123456789101112/*** @param o1 the first object to be compared.* @param o2 the second object to be compared.* @return a negative integer, zero, or a positive integer as the* first argument is less than, equal to, or greater than the* second.* @throws NullPointerException if an argument is null and this* comparator does not permit null arguments* @throws ClassCastException if the arguments' types prevent them from* being compared by this comparator.*/int compare(T o1, T o2); 可以看到当有入参为null时就会抛出异常 使用 新建比较类 实现此接口，重写方法 自己调用该方法进行比较或者作为Collections.sort等入参 示例代码:结果: java.util.Comparable只有一个方法12345678910/*** @param o the object to be compared.* @return a negative integer, zero, or a positive integer as this object* is less than, equal to, or greater than the specified object.** @throws NullPointerException if the specified object is null* @throws ClassCastException if the specified object's type prevents it* from being compared to this object.*/public int compareTo(T o); 使用 实现接口，重写方法 调用该方法 示例代码:结果: 扩展java.util.Collections.sort最终还是会调用java.util.Arrays里的sort方法，我们跟着他在源码中跳几下，看看这个过程 step0 step1 step2 step3 没有比较器 介绍 /** * Sorts the specified array of objects into ascending order, according * to the {@linkplain Comparable natural ordering} of its elements. * All elements in the array must implement the {@link Comparable} * interface. Furthermore, all elements in the array must be * &lt;i&gt;mutually comparable&lt;/i&gt; (that is, {@code e1.compareTo(e2)} must * not throw a {@code ClassCastException} for any elements {@code e1} * and {@code e2} in the array). 数组中的元素必须实现Comparable接口 使用 有比较器我这里看的是 TimSort.sort继续看 binarySort step4哇，这里还有好多的sort啊，看的我脑袋都大了，over]]></content>
      <tags>
        <tag>comparator/comparable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的transient]]></title>
    <url>%2F2018%2F08%2F10%2Ftransient-in-java%2F</url>
    <content type="text"><![CDATA[transient本意英 [ˈtrænziənt] 美 [ˈtrænziənt]adj. 短暂的;转瞬即逝的;临时的n. 临时旅客;瞬变现象;候鸟 序列化与反序列化要说transient，就要说序列化和反序列化维基百科的定义 序列化（serialization）在计算机科学的资料处理中，是指将数据结构或物件状态转换成可取用格式（例如存成档案，存于缓冲，或经由网络中传送），以留待后续在相同或另一台计算机环境中，能恢复原先状态的过程。依照序列化格式重新获取字节的结果时，可以利用它来产生与原始物件相同语义的副本。对于许多物件，像是使用大量参照的复杂物件，这种序列化重建的过程并不容易。面向对象中的物件序列化，并不概括之前原始物件所关联的函式。这种过程也称为物件编组（marshalling）。从一系列字节提取数据结构的反向操作，是反序列化（也称为解编组,deserialization, unmarshalling）。 序列化在计算机科学中通常有以下定义: 对同步控制而言，表示强制在同一时间内进行单一存取。 在数据储存与传送的部分是指将一个对象存储至一个储存媒介，例如档案或是记亿体缓冲等，或者透过网络传送资料时进行编码的过程，可以是字节或是XML等格式。而字节的或XML编码格式可以还原完全相等的对象。这程序被应用在不同应用程序之间传送对象，以及服务器将对象储存到档案或数据库。相反的过程又称为反序列化。 还不是很清楚，引用这篇博客说的: 序列化：将一个对象转换成一串二进制表示的字节数组，通过保存或转移这些字节数据来达到持久化的目的。 反序列化：将字节数组重新构造成对象。 java实现序列化及反序列化java中要实现对象序列化只需要实现java.io.Serializable接口，想要更深的了解Serializable接口，只需要看其相关API或javadoc即可，下面我们来捡一些我看得懂的重要内容看 Serializability of a class is enabled by the class implementing thejava.io.Serializable interface. Classes that do not implement thisinterface will not have any of their state serialized or deserialized.All subtypes of a serializable class are themselves serializable. Theserialization interface has no methods or fields and serves only toidentify the semantics of being serializable. 只有实现了Serializable接口才能序列化，所有实现了Serializable接口的类的子类也能序列化，该接口没有任何方法和属性，只是用作标识能够序列化，这种用法在java中应该还有其他的，现在没影响了。 To allow subtypes of non-serializable classes to be serialized, thesubtype may assume responsibility for saving and restoring the stateof the supertype’s public, protected, and (if accessible) packagefields. The subtype may assume this responsibility only if the classit extends has an accessible no-arg constructor to initialize theclass’s state. It is an error to declare a class Serializable if thisis not the case. The error will be detected at runtime. 大意就是上面说的，实现了Serializable接口的类的子类(没有明确实现Serializable的)要想能够序列化，那么其父类必须要有一个没有参数的子类能够访问的构造方法，下面写个简单的示例:父类没有无参构造函数，子类直接报错了，下面在父类中添加无参构造函数可以看到没报错了 Classes that require special handling during the serialization and deserialization process must implement special methods with these exact signatures: private void writeObject(java.io.ObjectOutputStream out) throws IOException; private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException; private void readObjectNoData() throws ObjectStreamException; 想要自定义序列化或反序列化的过程，需要在类中实现这些方法。 默认的序列化和反序列化的方法分别在java.io.ObjectInputStream/java.io.ObjectOutputStream中方法名称分别为defaultReadObject/defaultWriteObject The serialization runtime associates with each serializable class aversion number, called a serialVersionUID, which is used duringdeserialization to verify that the sender and receiver of a serializedobject have loaded classes for that object that are compatible withrespect to serialization. If the receiver has loaded a class for theobject that has a different serialVersionUID than that of thecorresponding sender’s class, then deserialization will result in anInvalidClassException. A serializable class can declare its ownserialVersionUID explicitly by declaring a field named“serialVersionUID” that must be static, final, and of type long: ANY-ACCESS-MODIFIER static final long serialVersionUID = 42L; 大意为每个可序列化的类必须要有一个叫做 serialVersionUID 的属性，接收端在进行反序列化时会判断序列化中对象的UID和本地的相应类的UID是否相同，如果不同会抛出InvalidClassException异常，该属性必须叫这个名字，而且是 static,final,long类型的 If a serializable class does not explicitly declare a serialVersionUID, then the serialization runtime will calculate a default serialVersionUID value for that class based on various aspects of the class, as described in the Java(TM) Object Serialization Specification. However, it is strongly recommended that all serializable classes explicitly declare serialVersionUID values, since the default serialVersionUID computation is highly sensitive to class details that may vary depending on compiler implementations, and can thus result in unexpected InvalidClassExceptions during deserialization. Therefore, to guarantee a consistent serialVersionUID value across different java compiler implementations, a serializable class must declare an explicit serialVersionUID value. It is also strongly advised that explicit serialVersionUID declarations use the private modifier where possible, since such declarations apply only to the immediately declaring class–serialVersionUID fields are not useful as inherited members. Array classes cannot declare an explicit serialVersionUID, so they always have the default computed value, but the requirement for matching serialVersionUID values is waived for array classes. 这一段很长，主要就是说这个UID很重要，如果你没有明确声明，那么jvm会在序列化时候，计算一个UID作为默认的，但是这个计算方式非常依赖编译器，并且产生的结果和这个类本身(即属性，方法什么的)有很大的关系，所以这样一来，不同的jvm对同一个类默认生成的UID可能不同，而且一旦修改了类内容，那么肯定新的UID非常可能会和旧UID不同，这样很容易导致反序列化失败，我这里做一个修改类的例子:很正常的一个类，下面是序列化和反序列化反序列化结果:然后我把Book类中的test字段删除，发送端的已经保存到dest1.txt中了，我现在修改Book类相当于是接收端修改了类，然后接收端再从dest1.txt反序列化，结果:可以看到报异常了，所以说，这个serialVersionUID还是自己声明一个比较好 transient关键字transient说来应该就是为序列化和反序列化服务的，当一个字段声明为transient时，在默认的序列化和反序列化过程中就会跳过该字段，但并不是说该字段就不能被序列化了，我们可以自定义序列化过程来使得其进行序列化，还记得前边的 writeObject/readObject方法吧，我们可以在这些方法中自定义序列化过程。这样一来，我们对于序列化的掌握就更加深了，对于一般的字段，用默认序列化方法即可，对于一些特殊的字段，比如用户密码什么的，我们可以对其声明transient，然后在自定义序列化中对其进行一些加密或其他处理在序列化。其实在上边的示例中仔细看就会发现Book类中flag字段是 transient的，但是在反序列时我依然可以读取该字段，就是因为我自定义了序列化/反序列化: 序列化扩展在上面引用的序列化定义中写道”将一个对象转换成一串二进制表示的字节数组”，那么如今我把这个二进制的字节数组写到了dest1.txt文件，那么我们为什么不看一看文件内容呢这里有两个文件，左边的dest.txt是没有自定义序列化的，右边的是自定义了序列化的，所以右边比左边多出了一个flag，值为1，下边对文件dest1.txt内容进行分析，还是参考了这篇博客 序列化文件头 AC ED：STREAM_MAGIC序列化协议 00 05：STREAM_VERSION序列化协议版本 73：TC_OBJECT声明这是一个新的对象 序列化的类的描述 72：TC_CLASSDESC声明这里开始一个新的class 00 04：十进制的4，表示class名字的长度是4个字节 42 6F 6F 6B：类名，包括包名，但是我这里没加包就没有 DB 46 ……85 65：八个字节，long类型的长度，表示serialVersionUID 03： 00 02：该类所包含的域的个数，可以看到这里不包括transient的字段 对象中各个属性项的描述 49：字符”I”，表示该属性是一个基本类型 00 06：十进制的6，表示属性名的长度 62 6F 6F 6B 49 64：字符串“bookId”，属性名 4C：字符”L”，表示该属性是一个对象类型而不是基本类型 00 08：属性名长度 八个字节：”bookName” 74：TC_STRING，代表一个new String，用String来引用对象 该对象父类的信息(这里我不是很懂) 00 12：十进制的18，表示父类的长度 4C 6A 61 … 6E 67 3B：“L/java/lang/String;”表示的是父类属性 78：TC_ENDBLOCKDATA，对象块结束的标志 70：TC_NULL，说明没有其他超类的标志 对象的属性项的实际值如果属性项是一个对象，这里还将序列化这个对象，规则和第2部分一样 00 00 00 01：bookId的值，为1，我才基本类型就直接显示值 74：前边说是代表一个new String 00 05：应该是new String 的长度 62 6F 6F 6B 31：bookName的值”book1”在后边就是自定义序列化增加的内容了 77：w，应该是标识write 04：表示写了4个字节 00 00 00 01：表示flag的值，为1 78：对象块结束的标志 额外 在自定义序列化中，可以看到上边我用的是writeInt，写4个字节，还有一个write(int)方法，只写一个字节，当参数超过一个字节时，只写低8位，看一个示例：我把上边的flag改为 77777777，很明显这个数超过8个字节了，其16进制为04a2cb71，我们看一下写到文件中的内容：只写了一个71 static变量也不会被序列化 over]]></content>
      <tags>
        <tag>transient关键字</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的static]]></title>
    <url>%2F2018%2F08%2F08%2Fstatic-in-java%2F</url>
    <content type="text"><![CDATA[java中的static想必很常见了，但是若要问到其具体的用法，你又能说出几种呢 static修饰变量方法这应该是最常见的一种用法了，当类中的属性或方法被static修饰后，就变成了类属性，也就是说访问这些方法或属性不需要类的实例，直接 ClassName.fieldName/ClassName.methodName一般在访问这些静态变量或方法时，不推荐用类实例来访问示例: 12345678910111213141516171819202122232425262728293031public class StaticOne &#123; public static int flag = 123; private String hello; public void setHello(String hello) &#123; this.hello = hello; &#125; @Override public String toString() &#123; return "StaticOne&#123;" + "hello='" + hello + '\'' + "flag='" + StaticOne.flag + '\'' + '&#125;'; &#125; public static void main(String[] args) &#123; StaticOne staticOne1 = new StaticOne(); staticOne1.setHello("staticOne1"); System.out.println(staticOne1.toString()); StaticOne staticOne2 = new StaticOne(); staticOne2.setHello("staticOne2"); System.out.println(staticOne2.toString()); StaticOne.flag = 111; System.out.println(staticOne1.toString()); System.out.println(staticOne2.toString()); &#125;&#125; 运行结果: StaticOne{hello=’staticOne1’flag=’123’}StaticOne{hello=’staticOne2’flag=’123’}StaticOne{hello=’staticOne1’flag=’111’}StaticOne{hello=’staticOne2’flag=’111’} 可以看到类实例共享类静态属性，类中的静态成员变量在jvm有特定的存放位置，叫做 方法区 static修饰代码块static修饰的代码块在类被加载时就运行，而且只在类被加载到jvm中时运行一次，后续创建该类实例时不再运行示例: 12345678910111213public class StaticTwo &#123; public StaticTwo() &#123; System.out.println(System.currentTimeMillis()); &#125; static &#123; System.out.println(System.currentTimeMillis()); System.out.println("this is static block in class StaticTwo"); &#125; public static void main(String[] args) &#123; StaticTwo staticTwo1 = new StaticTwo(); StaticTwo staticTwo2 = new StaticTwo(); &#125;&#125; 运行结果: 1533725267598 this is static block in class StaticTwo15337252675981533725267598 虽然时间都是一样的，但是还是可以看到，static代码块里的代码在实例化对象之前执行，我猜静态代码块一般用来初始化一些数据用 在面试题中也会出现，父类子类里边都有静态代码块、代码块、构造函数，让你说说他们的执行顺序让我们来改造一下示例代码:123456789101112131415public class StaticTwo &#123; public StaticTwo() &#123; System.out.println("this is constructor " + System.currentTimeMillis()); &#125; static &#123; System.out.println("this is static block in class StaticTwo " + System.currentTimeMillis()); &#125; &#123; System.out.println("this is current block in class StaticTwo " + System.currentTimeMillis()); &#125; public static void main(String[] args) &#123; StaticTwo staticTwo1 = new StaticTwo(); StaticTwo staticTwo2 = new StaticTwo(); &#125;&#125; 很简单，就加了一个普通的代码块，先来看看执行结果吧: this is static block in class StaticTwo 1533725730951this is current block in class StaticTwo 1533725730951this is constructor 1533725730951this is current block in class StaticTwo 1533725730951this is constructor 1533725730951 很容易看出一些规律，在一个类中，每次新建类实例时，都会执行一遍普通代码块，再执行构造方法接着改造，加入父子类: 123456789101112131415161718192021222324252627public class StaticTwo &#123; public StaticTwo() &#123; System.out.println("this is StaticTwo constructor " + System.currentTimeMillis()); &#125; static &#123; System.out.println("this is static block in class StaticTwo " + System.currentTimeMillis()); &#125; &#123; System.out.println("this is current block in class StaticTwo " + System.currentTimeMillis()); &#125;&#125;class StaticTwoChild extends StaticTwo&#123; public StaticTwoChild() &#123; System.out.println("this is StaticTwoChild constructor " + System.currentTimeMillis()); &#125; static &#123; System.out.println("this is static block in class StaticTwoChild " + System.currentTimeMillis()); &#125; &#123; System.out.println("this is current block in class StaticTwoChild " + System.currentTimeMillis()); &#125; public static void main(String[] args) &#123; StaticTwoChild staticTwoChild1 = new StaticTwoChild(); StaticTwoChild staticTwoChild2 = new StaticTwoChild(); &#125;&#125; 运行结果: this is static block in class StaticTwo 1533726245985this is static block in class StaticTwoChild 1533726245986this is current block in class StaticTwo 1533726245986this is StaticTwo constructor 1533726245986this is current block in class StaticTwoChild 1533726245986this is StaticTwoChild constructor 1533726245986this is current block in class StaticTwo 1533726245986this is StaticTwo constructor 1533726245986this is current block in class StaticTwoChild 1533726245986this is StaticTwoChild constructor 1533726245986 分析: java中扩展类的初始化过程是这样的，最初虚拟机会依次递推找到最上层的父类，执行完类加载与静态成员的初始化；当main函数中执行代码，产生某个子类对象时，再依次递归找到最上层的父类先进行成员初始化（对象引用没有直接赋值就初始化为Null）,再调用相应的构造器产生对象，然后逐层的进行对象初始化直到最底层的子类。 所以我们可以看到，jvm在加载StaticTwoChild时，能发现它有父类StaticTwo，所以先去加载他的父类，他的父类没有显示的父类，所以就直接加载，然后在下去加载StaticTwoChild，所以输出前两行是父类静态代码块-&gt;子类静态代码块 子类在执行构造函数时，会先找父类的非默认构造方法并执行，所以下边输出结果就是先父类即StaticTwo的构造方法，再是子类即StaticTwoChild的构造方法，上边也说过了，普通代码块在每次实例化对象时都会最先执行，所以是父类普通代码块-&gt;父类构造方法-&gt;子类普通代码块-&gt;子类构造方法 static修饰内部类内部类就是在一个类的内部，像定义变量方法那样，定义一个类，就叫内部类。其实在JDK中就有很多的内部类，尤其是在集合类中，比如下边:还有很多就不放图了。这里有会涉及静态内部类和普通内部类的区别，这里简单的说几点基本的吧: 创建实例方式不同 静态内部类中只能访问外部类中静态成员，普通内部类都行 普通内部类中不能有static关键字，但是静态内部内中静不静态都行 静态类有什么用呢？我也不清楚，抄一下别人的 内部类一般只为其外部类使用； 内部类提供了某种进入外部类的窗户； 也是最吸引人的原因，每个内部类都能独立地继承一个接口，而无论外部类是否已经继承了某个接口。因此，内部类使多重继承的解决方案变得更加完整。可能还是我阅读量太少，并没有体会到内部类的精髓。 静态引入想来这也是最不常见的吧，我也不记得第一次在哪看到的了，不过还有影响的是在一个测试类中引入的断言，应该是这样的:1import static org.junit.Assert.*; 使用静态引入可以方便我们编码，比如下边的示例123456import static java.lang.System.out;public class StaticFour &#123; public static void main(String[] args) &#123; out.println(); &#125;&#125; 不用多说了吧。]]></content>
      <tags>
        <tag>static关键字</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap如何产生环]]></title>
    <url>%2F2018%2F07%2F31%2Fring-in-hashMap%2F</url>
    <content type="text"><![CDATA[HashMap本身不是线程安全的，所以高并发的情况下不应该使用HashMap，但是这里还是看了一下HashMap可能会产生的问题及其原因。这里讨论的主要是jdk1.7版本的HashMap。 正常情况下HashMap当HashMap中的元素超过其阀值时，HashMap要进行扩容，进行resize()操作, 下边的是jdk1.7的实现 1234567891011121314151617void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K, V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do &#123; Entry&lt;K, V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125; &#125; 单线程下的resize()接下来进行resize()操作，首先e指向A，next指向B，然后把e放到新的HashMap中结束这一次迭代时把e指向B就这样循环的把每一个Entry都放到新的HashMap中最终变成这样：注意while循环的结束条件为 e==null 并发下的HashMap假设有两个线程对上边的HashMap进行操作，在他们运行时，都知道要进行resize()，首先是线程1：刚把e和next赋值，cpu就被线程2抢走了，而且线程2还比较厉害，一直把resize()完成才退出，那么线程2结束时我们的HashMap就变成这样了：这里线程2对HashMap的操作会影响线程1中的e和next，因为操作的都是同一块内存然后线程1继续执行，但是他不知道e和next的位置已经发生了变化，甚至不知道他已经不用再resize()了，需要注意的是，在resize()过程中，新表在建立过程中会把旧表中的Entry都置为null，但是线程1可不管那么多，他只知道e和next还指向内存块，他还要进行resize(). 然后线程1在线程2建立的新表的基础上继续resize()，要注意的是，此时线程1在循环之前就把他的新表建立了，线程1继续执行的效果如下把A取出放入新表中，然后e指向next即B，注意此时B的next为A，然后新一轮迭代中 1next = e.next 所以next指向了A 下一轮迭代中，e指向next即A，next指向null，然后用头插法把A插到头，结果就变成这样了！！ 虽然建表的过程就此结束了，但是新表中含有了环！！那么下次只要有查询的需求并且查到了这个环，那么就会一直查下去造成死循环！ 上边的图参考自其他的blog，现在再看有些复杂了，重新画下： 首先是线程1过来想要rehash()，刚标好e和next: 线程2抢占了线程1，也要操作这个HashMap，并且也需要rehash()，首先一点，HashMap是个对象，放在堆中，各个线程访问的都是一样： 线程2执行完rehash()后，又到线程1接着跑，但是此时线程1不知道别的线程已经完成了rehash()，接着之前的工作，此时线程1之前做的标记还☞着原本的节点： 采用头插法将A:3插到了前边，且A:3.next指向了B:7，需要注意的是B:7.next由于线程2的修改指向了A:3，此时环就形成了。 总结总的说来，resize()会产生环主要是把元素放到新桶中用的头插法，在1.8中已经改进了，并且1.8一般不会再产生环了。 参考https://mailinator.blogspot.com/2009/06/beautiful-race-condition.html]]></content>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo每次deploy后需要重新绑定自定义域名]]></title>
    <url>%2F2018%2F07%2F20%2Fhexo_deploy%2F</url>
    <content type="text"><![CDATA[在hexo目录下的source下新建一个CNAME文件，写上自定义的域名即可。]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的nc]]></title>
    <url>%2F2018%2F07%2F20%2Fnc%2F</url>
    <content type="text"><![CDATA[NC，组内共享工具 用在linux下，主要有三个功能，扫描端口，传输文件，监控网速 这里主要说一下传输文件 环境由于是用在linux下的，我就用虚拟机来做实验，用Virtualbox建了两台Centos7 要求： 这两台机子能互相ping通 最好可以联网，因为我的Centos7没有自带nc工具 如果能ping通主机就更好了，这样可以使用xshell等连接工具，操作更方便 接下来先说说让这些机器相互ping通看了教程，用两块网卡比较方便，一块NAT，一块Host-Only，我的弊见就是NAT用来访问外网，Host-Only和主机打交道有一点要注意，启动网络连接是在你没启动虚拟机时选择的，虚拟机跑起来了就无法添加网卡了 配置虚拟机中的网卡在 /etc/sysconfig/network-scripts/ 下可以看到这样的两个网卡，ifcfg-enp0s3和ifcfg-enp0s8，分别代表NAT和Host-Only的网卡 两块网卡都要修改画红框的是需要注意的地方，Host-Only网卡中需要配置静态ip，此ip需要根据主机中VirtualBox Host-Only Network网卡的ip设置，可以看到这两个ip是处于同一个网段中的。 重启网络service network restart 这时候可以尝试ping baidu.com和主机，注意ping主机时ping的是以太网适配器的ip而不是VirtualBox Host-Only Network的ip 然后用同样的套路在造一个Centos7现在主机和虚拟机可以互相ping通，虚拟机可以ping通外网，但是我这里虚拟机之间不能ping通了，可能是两台虚拟机的主机名是一样的？我没有细查，修改了/etc/hosts文件然后再重启网络，虚拟机之间就可以ping通了 环境终于好了，下面用nc，我主要试了文件传输功能这里需要注意的是我新造的虚拟机是开启了防火墙的，所以下边监听端口的话，要先开发该端口，所以有涉及到Centos7开放端口12firewall-cmd --zone=public --add-port=9999/tcp --permanentfirewall-cmd reload #刷新规则 1nc -l 9999 &gt; test.txt 机器A监听9999端口，当有动静的时候，把收到的内容写到test.txt文件中 1nc 192.168.56.100 9999 &lt; hello.txt 机器B使用nc把hello.txt 传送给机器A，机器A把hello.txt中的内容写入到test.txt中 当然也可以翻转一下1nc -l 9999 &lt; hello.txt 这样当有人连接该端口时，就把hello.txt发给他 个人感觉传输功能比较使用，可能是我眼界现在还太狭隘了，没有理解其他功能的实际用处。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>nc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux删除查找到的所有文件及目录]]></title>
    <url>%2F2018%2F07%2F08%2Frm%2F</url>
    <content type="text"><![CDATA[这里需要用find命令，因为find命令后边可以跟其他可执行的命令 Step1. 首先根据关键字查找特定的文件及目录我这里用steam作示范，这样就能找到所有包含’steam’关键字的文件及目录 Step2. 在后边追加操作命令1) 追加命令格式为: -exec command {} \;在{}和\之间必须要有空格，否则会报错. 2) xargs用于从 标准输入获得参数并且传递给后面的命令，这里使用的命令是 rm，然后由rm删除前面选择的文件]]></content>
      <tags>
        <tag>linux</tag>
        <tag>find</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error/exception in java]]></title>
    <url>%2F2018%2F06%2F24%2Ferror_exception%2F</url>
    <content type="text"><![CDATA[java异常分为Error和Exception，二者都是继承自Throwable 先来看看Exception： The class Exception and its subclasses are a form of Throwable thatindicates conditions that a reasonable application might want tocatch. The class Exception and any subclasses that are not also subclasses ofRuntimeException are checked exceptions. Checked exceptions need to bedeclared in a method or constructor’s throws clause if they can bethrown by the execution of the method or constructor and propagateoutside the method or constructor boundary. 可以知道Exception的子类除了RuntimeException 都是检查型异常，在程序中需要捕获处理或者抛给上层处理。 再看看RuntimeException RuntimeException is the superclass of those exceptions that can bethrown during the normal operation of the Java Virtual Machine. RuntimeException and its subclasses are unchecked exceptions.Unchecked exceptions do not need to be declared in a method orconstructor’s throws clause if they can be thrown by the execution ofthe method or constructor and propagate outside the method orconstructor boundary. 可以看到不要求在编译的时候处理。 Error的定义 An Error is a subclass of Throwable that indicates serious problemsthat a reasonable application should not try to catch. Most sucherrors are abnormal conditions. The ThreadDeath error, though a“normal” condition, is also a subclass of Error because mostapplications should not try to catch it. A method is not required to declare in its throws clause anysubclasses of Error that might be thrown during the execution of themethod but not caught, since these errors are abnormal conditions thatshould never occur. That is, Error and its subclasses are regarded asunchecked exceptions for the purposes of compile-time checking ofexceptions. Error是程序中严重的错误，任何合理的程序都不能去捕获Error。]]></content>
      <tags>
        <tag>error/exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netstat 命令]]></title>
    <url>%2F2018%2F06%2F22%2Fnetstat%2F</url>
    <content type="text"><![CDATA[Print network connections, routing tables, interface statistics,masquerade connections, and multicast memberships netstat用来显示网络相关的信息，如网络连接，路由表，接口统计，伪装链接和广播成员 常用的几个选项 –numeric , -n Show numerical addresses instead of trying to determinesymbolic host,port or user names. 不解析名称，显示数字就行 -p, –program Show the PID and name of the program to which each socket belongs. 显示端口(?)所属的程序的pid和名字 -l, –listening Show only listening sockets. (These are omitted by default.) 只显示正在监听的端口 {-t|–tcp} {-u|–udp} 分别表示显示TCP/UDP传输协议的连接 一些在我看来很高级的用法：查看连接某服务端口最多的的IP地址： netstat -ntu | grep :80 | awk ‘{print $5}’ | cut -d: -f1 | awk‘{++ip[$1]} END {for(i in ip) print ip[i],”\t”,i}’ | sort -nr TCP各种状态列表： netstat -nt | grep -e 127.0.0.1 -e 0.0.0.0 -e ::: -v | awk ‘/^tcp/{++state[$NF]} END {for(i in state) print i,”\t”,state[i]}’ 查看phpcgi进程数，如果接近预设值，说明不够用，需要增加： netstat -anpo | grep “php-cgi” | wc -l]]></content>
      <tags>
        <tag>linux</tag>
        <tag>netstat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git clone branch]]></title>
    <url>%2F2018%2F06%2F20%2Fgit_clone%2F</url>
    <content type="text"><![CDATA[在使用git clone项目后，查看本地分支，只有master分支，远程仓库的其他分支并没有克隆下来，如果需要其他分支可以用下面两种方法 方法一git branch -a 先查看当前远端分支情况 git checkout origin/xxx 选择远端xxx分支 git branch xxx 创建本地xxx分支 git checkout xxx 选择新创建的分支就可以了 方法二git clone -b &lt;branch-name&gt; &lt;remote&gt;]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX下的JOB, FG, BG, &]]></title>
    <url>%2F2018%2F06%2F12%2Fjob%2F</url>
    <content type="text"><![CDATA[在使用linux过程中，偶尔会不自觉的按ctrl + z，这时候会显示[1]+ Stopped 之类的，而且如果这时候你在做一些操作，比如编辑文件等，会直接回到命令状态。那么之前的工作去哪了呢? 去了Stopped于后台中了。 这是输入jobs命令，就可以查看Linux中的任务列表及任务状态，包括后台运行的任务。 bg(background) 将后台暂停的任务启动，在后台继续运行 fg(foreground) 将后台任务调至前台执行 &amp; 放在命令的最后，用于将任务放在后台执行]]></content>
      <tags>
        <tag>linux</tag>
        <tag>bg</tag>
        <tag>fg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git push的完整形式]]></title>
    <url>%2F2018%2F05%2F24%2Fgit_push%2F</url>
    <content type="text"><![CDATA[现在的情况是，本地有两个分支：master、div， 远程仓库有一个分支：master，本地master分支和远程master分支建立有跟踪联系，这样本地master分支提交时直接git push(只有一个远程仓库的情况下) 那么div分支也想提交到远程master怎么办呢，先试试直接git push：提示信息很清楚了 这里使用命令 git push origin HEAD:master 即可 而HEAD指向的是当前的分支，git可以通过HEAD找到当前的分支名，所以该命令相当于 git push origin div:master ==git push/pull &lt;远程主机名&gt; &lt;源分支&gt;:&lt;目的分支&gt;== 是git push常用的精简命令的完整格式，当然还可以加git push的各种 []，这里就不说了。 说实话，我平时只顾着用git push ，连git push不省略的格式是什么都不记得了，唉. 2018.06.20 更新 在推送前，我们可以使用命令 git push -u &lt;远程主机名&gt; &lt;分支名&gt; 其中-u 参数效果：如果当前分支与多个主机存在追踪关系，则可以使用-u选项指定一个默认主机，这样后面就可以不加任何参数使用git push. –set-upstream 是用来和远程分支建立追踪关系]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX下配置环境变量]]></title>
    <url>%2F2018%2F05%2F21%2Flinux_env%2F</url>
    <content type="text"><![CDATA[有些东西不自己写一下，总是会忘记，当然写了也可能还是会忘，但是找起来印象会深一点吧。之前在需要配置环境变量的时候就直接查了一下，完成配置后就没管了，最近再次想到这个问题，结果已经忘记该怎么配置了。所以什么东西都是写一下比较好吧. 方式一：使用export使用export命令直接修改PATH变量 方式二：修改/etc/profile 如果要立即生效需要执行命令 source /etc/profile 使用这种方式，所有用户都会受影响,当第一个用户登录时,该文件被执行. 类似的还有/etc/enviroment文件，影响所有用户 方式三：修改~/.bashrc 同样立即生效需要： source ~/.bashrc 专属于个人bash shell的信息，当该用户登录时以及每次打开新的shell时,该文件被读取. 类似的还有~/.profile，当用户登录时,该文件仅仅执行一次!默认情况下,它设置一些环境变量,然后执行用户的.bashrc文件.]]></content>
      <tags>
        <tag>path</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[笔记本安装SSD, 并在SSD中安装系统]]></title>
    <url>%2F2018%2F05%2F02%2Fssd%2F</url>
    <content type="text"><![CDATA[前言很早就想买个ssd了，经过一些事情之后，我也没那么多顾虑，想买就买了。本来打算是在ssd中重装一个系统的，但是后来考虑到电脑里边有些东西重装系统后再搞很麻烦，就没有选择重装系统了，但是突然想试试Linux，就选了Ubuntu，安在了ssd里边，把电脑搞成双系统，所以这篇文章有这几个部分吧：笔记本安装ssd、安装Ubuntu系统、笔记本实现双系统。 笔记本装ssd我的笔记本没有空出的位置装ssd，所以就把光驱拆了，买ssd时候把电脑型号发给客服，客服会告诉你用什么规格的支架。然后就是拆光驱，把ssd放进支架里，在把支架安在原来放光驱的地方，挺简单的。 对了，还有关于笔记本是否能发挥ssd性能的几个小点，首先是接口，就是光驱那个接口最好是sata3接口的; 然后是bios里有个地方IDE要设置成 AHCI模式。 装好之后可以下载一些测试工具，这里我忘了我用的啥了，查一下就知道。 安装Ubuntu系统我用的是u盘作为启动盘，所以这里就讲讲这种方式。 首先下载ubuntu系统iso， 然后用UltraISO制作启动盘，制作好后，保持u盘插入的状态，重启电脑，这时候要进入BIOS系统(具体按哪个键可以搜一下，我的华硕是F2)，在BIOS中更改启动盘，选择刚刚的u盘，应该会有名字的。 启动之后应该就是安装的界面了，具体安装过程怎么选择我也忘了，这里没有截图，捡我记得的写。我在安装过程中，提示过我一个东西，好像是有个格式不对，我选择的跳过还是什么的，反正不是确认。我那时候出现这个问题，就去google了，说是启动盘要用一个别的软件做才行，然后我信了他的邪，重新一边还是这样。后边再有印象的就是分区了。 首先说明一点，分区分区，分的是你电脑里，没有进行过初始化的区域，当你的ssd刚安电脑里的时候，你用硬盘管理看到这块磁盘是未分配状态的，那么在安装系统过程中就会使用这些未分配的区域。 Linux分区，应该是安装系统中比较重要的一点？我也是按照网上的一般教程进行分区的，分了四个区: /, /boot, /home, /swap， 另外在分区时，需要注意的是swap分区需要选择”交换空间”，其他三个就按默认的Ext4日志文件系统。在说一下这四个分区的含义：/，主分区相当于windows的c盘; /boot 引导分区; /home 用户存储数据用，需要大一点; /swap 相当于电脑的内存，设置为内存的1.5～2倍。分区设置完毕后，下方还有一项“安装启动引导器的设备”，默认是ubuntu引导windows，也就是开机启动显示的ubuntu的样子，然后选择是ubuntu还是window，如果想windows引导ubuntu，则“引导器的设备”选择之前/boot分区的名字。 实现双系统前面的说明了，我是从windows引导ubuntu的，所以还需要一些工具来设置ubuntu的启动选项，这里我用的是EasyBCD，打开easyBCD，选择add new entry，选择linux/BSD，name那里填Ubuntu（可自行填写）。device(驱动器)这一栏选择我们刚创建的“/boot”分区（200MB那个，可能大小会有一点出入）。最后点击Add entry（添加条目）。最后还有一点可能会出错的地方，就是设置了引导后，选择ubuntu却无法正常启动，具体原因我不记得了，应该是在新建ubuntu条目时有个选项有问题，具体是什么，我后面在看看。 好了，大概就是这样了，有很多东西没有讲清楚，因为google一下总会有讲的清楚的，我在这里也只是理了一下我做这些事情的一个过程，就是一个简单的思路。]]></content>
      <tags>
        <tag>ssd</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
</search>
