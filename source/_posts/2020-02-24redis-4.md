---
title: redis--配置管理
date: 2020-02-24 17:22:35
tags: 
- redis
---

通过`redis`的配置文件更加深入的了解`redis`.

<!--more-->

### 基础配置

1. `port 6379` 可以自定启动端口

2. `daemonize yes` 以守护进程的方式启动`redis`
3. `logfile ""` 指定日志文件，如果为空，输出到标准输出
4. `dir` 指定工作目录，会将比如日志文件，数据库备份等存放在该目录下，需要先手动创建

### 持久化

利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制称为持久化。

持久化的方式：

1. 数据（快照）-----> RDB
2. 过程（日志）-----> AOF

### RDB

命令 ：`save` 手动执行一次保存操作

效果 ：在指定的`dir`目录下生成`dump.rdb`文件

注意 ：`save`指令的执行会阻塞当前`redis`服务器，线上环境不建议使用

命令 ：`bgsave` 异步执行快照操作

效果 ：调用`fork()`产生一个子进程完成具体的`save`操作，完成后给`redis`返回消息，可以在日志文件中查看



#### 相关配置

1. `rdbcompression yes` 采用`LZF`压缩字符串对象
2. `rdbchecksum yes` `redis5`之后采用`CRC64`对数据文件进行校验，会影响`10%`左右的性能，如果关闭，数据末尾的校验数据会被设置为`0`，跳过验证
3. `dbfilename dump.rdb` 设置`dump`数据库生成的文件名
4. `stop-writes-on-bgsave-error yes` 持久化出现问题时是否停止备份

#### 部分源码

先只考虑没有冲突的情况（没有额外的`saving/rewrite`）

```c
/* If there is not a background saving/rewrite in progress check if
         * we have to save/rewrite now. */
for (j = 0; j < server.saveparamslen; j++) {   // 循环所有的 save seconds changes 配置
    struct saveparam *sp = server.saveparams+j;   

    /* Save if we reached the given amount of changes,
             * the given amount of seconds, and if the latest bgsave was
             * successful or if, in case of an error, at least
             * CONFIG_BGSAVE_RETRY_DELAY seconds already elapsed. */
    if (server.dirty >= sp->changes &&
        server.unixtime-server.lastsave > sp->seconds &&
        (server.unixtime-server.lastbgsave_try >
         CONFIG_BGSAVE_RETRY_DELAY ||          // 默认是5秒
         server.lastbgsave_status == C_OK))    
    // 前边两个条件是 如果所作的修改大于指令指定次数并且距离上次保存时间也大于指定的时间
    {
        serverLog(LL_NOTICE,"%d changes in %d seconds. Saving...",
                  sp->changes, (int)sp->seconds);
        rdbSaveInfo rsi, *rsiptr;
        rsiptr = rdbPopulateSaveInfo(&rsi);
        rdbSaveBackground(server.rdb_filename,rsiptr);  // 在这里边调用了fork创建子进程进行bgsave
        break;
    }
}
```

如果操作没有`error`的话：

1. 两次保存之间至少要间隔`sp->seconds`秒，即使到目前为止写的次数已经超过了`sp->changes`
2. 经过`sp->seconds`秒并不会重置`server.dirty`已经写的次数

之前还在想如果设置的`save 10 2`，那么只要我不在`10s`内做两次写操作，那不就不会`save`了？  

= =。

#### 特殊启动形式

1. 全量复制
2. 服务器运行过程中重启 `debug reload` （在客户端运行指令，下同）
3. 关闭服务器时指定保存数据 `shutdown save`

#### 优点

1. 能进行压缩，是一个紧凑的二进制文件，存储效率高
2. 其数据是`redis`在某个时间点的快照，适合于数据备份，全量复制等场景
3. 恢复速度比`AOF`快
4. 用于灾难恢复

#### 缺点

1. 无法做到实时持久化，可能会丢失数据
2. `bgsave`由于需要创建子进程，会消耗一定的性能
3. 多版本`RDB`文件格式可能不同意，有无法兼容的现象

### AOF

`Append only file`持久化：以独立日志的方式记录每次写命令，重启时，重新执行`AOF`文件中的命令达到恢复数据的目的。能够解决数据持久化的实时性问题。

#### 命令

1. `appendonly yes/no`
2. `appendfilename "filename.aof"`
3. `appendfsync always/everysec/no`

#### 三种策略(appendfsync)

1. `no: don't fsync, just let the OS flush the data when it wants. Faster.`
2. `always: fsync after every write to the append only log. Slow, Safest`
3. `everysec: fsync only one time every second. Compromise.`      --------------->default

#### 重写

将`redis`进程内的数据转化为写命令同步到新`AOF`文件的过程。将对同一个数据的若干条命令执行结果转化为最终结果数据对应的指令进行记录，省去无效指令。

作用：

1. 降低磁盘占用量
2. 提高持久化效率
3. 降低数据恢复用时

重写规则：

1. 进程内已超时的数据不写
2. 忽略无效指令，只保留最终数据的写入命令
3. 对同一数据的多条写命令进行合并--------------->每条指令最多写64个元素

重写配置：

1. `auto-aof-rewrite-percentage 100`
2. `auto-aof-rewrite-min-size 64mb`
3. 涉及到的数据可以通过`info persistence`查看-------> `aof_current_size` , `aof_base_size`

![rewrite process by itheima](fig1.png)

### 对比

![compare by itheima](fig2.png)